{
  "snapshot_time": "2026-02-10T17:55:20.913886+00:00",
  "repository": "chtmp223/papers-feed",
  "objects": {
    "paper:nber.w34777": {
      "data": {
        "rating": "novote",
        "doi": "10.3386/w34777",
        "timestamp": "2026-02-08T01:07:44.172Z",
        "abstract": "Founded in 1920, the NBER is a private, non-profit, non-partisan organization dedicated to conducting economic research and to disseminating research findings among academics, public policy makers, and business professionals.",
        "url": "https://www.nber.org/papers/w34777",
        "authors": "Imke Reimers, Joel Waldfogel",
        "publishedDate": "2026/02/02",
        "title": "AI and the Quantity and Quality of Creative Products: Have LLMs Boosted Creation of Valuable Books?",
        "sourceId": "nber",
        "tags": [
          "Imke Reimers",
          "Joel Waldfogel"
        ],
        "paperId": "w34777",
        "journalName": "NBER Working Papers",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 12,
        "object_id": "paper:nber.w34777",
        "created_at": "2026-02-08T01:07:44+00:00",
        "updated_at": "2026-02-08T01:08:12+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.05125": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T01:23:36.193Z",
        "abstract": "Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.",
        "url": "https://arxiv.org/abs/2602.05125",
        "authors": "William F. Shen, Xinchi Qiu, Chenxi Whitehouse, Lisa Alazraki, Shashwat Goel, Francesco Barbieri, Timon Willi, Akhil Mathur, Ilias Leontiadis",
        "publishedDate": "2026/02/04",
        "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "paperId": "2602.05125",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 13,
        "object_id": "paper:arxiv.2602.05125",
        "created_at": "2026-02-08T01:23:36+00:00",
        "updated_at": "2026-02-08T01:23:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.21996": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:10:02.187Z",
        "abstract": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.",
        "url": "https://arxiv.org/abs/2601.21996",
        "authors": "Jianhui Chen, Yuzhang Luo, Liangming Pan",
        "publishedDate": "2026/01/29",
        "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
        "sourceId": "arxiv",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2601.21996",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 15,
        "object_id": "paper:arxiv.2601.21996",
        "created_at": "2026-02-08T02:10:02+00:00",
        "updated_at": "2026-02-08T02:10:26+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.12501": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:09:57.564Z",
        "abstract": "Reinforcement learning from human feedback (RLHF) has become an important technical and storytelling tool to deploy the latest machine learning systems. In this book, we hope to give a gentle introduction to the core methods for people with some level of quantitative background. The book starts with the origins of RLHF -- both in recent literature and in a convergence of disparate fields of science in economics, philosophy, and optimal control. We then set the stage with definitions, problem formulation, data collection, and other common math used in the literature. The core of the book details every optimization stage in using RLHF, from starting with instruction tuning to training a reward model and finally all of rejection sampling, reinforcement learning, and direct alignment algorithms. The book concludes with advanced topics -- understudied research questions in synthetic data and evaluation -- and open questions for the field.",
        "url": "https://arxiv.org/abs/2504.12501",
        "authors": "Nathan Lambert",
        "publishedDate": "2025/04/16",
        "title": "Reinforcement Learning from Human Feedback",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2504.12501",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 14,
        "object_id": "paper:arxiv.2504.12501",
        "created_at": "2026-02-08T02:09:57+00:00",
        "updated_at": "2026-02-08T02:10:16+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.03183": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.03183",
        "url": "https://arxiv.org/abs/2602.03183",
        "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
        "authors": "Hyunwoo Kim, Niloofar Mireshghallah, Michael Duan, Rui Xin, Shuyue Stella Li, Jaehun Jung, David Acuna, Qi Pang, Hanshen Xiao, G. Edward Suh, Sewoong Oh, Yulia Tsvetkov, Pang Wei Koh, Yejin Choi",
        "abstract": "Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.",
        "timestamp": "2026-02-08T15:57:27.140Z",
        "rating": "novote",
        "publishedDate": "2026/02/03",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 16,
        "object_id": "paper:arxiv.2602.03183",
        "created_at": "2026-02-08T15:57:27+00:00",
        "updated_at": "2026-02-08T15:59:45+00:00",
        "version": 1
      }
    },
    "paper:url.7BCFC2D3": {
      "data": {
        "sourceId": "url",
        "paperId": "7BCFC2D3",
        "url": "https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/",
        "title": "I Am Happier Writing Code by Hand",
        "authors": "Abhinav Omprakash",
        "abstract": "I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work and my phone. \u201cWhat\u2019s the point of it all?\u201d I thought, LLMs can generate decent-ish and correct-ish looking code while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow?",
        "timestamp": "2026-02-08T16:11:42.767Z",
        "rating": "novote",
        "publishedDate": "2026-02-07T15:30:23+02:00",
        "tags": [
          "essays"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 17,
        "object_id": "paper:url.7BCFC2D3",
        "created_at": "2026-02-08T16:11:42+00:00",
        "updated_at": "2026-02-08T16:12:02+00:00",
        "version": 1
      }
    },
    "paper:url.64A41AB2": {
      "data": {
        "sourceId": "url",
        "paperId": "64A41AB2",
        "url": "https://siddhantkhare.com/writing/ai-fatigue-is-real",
        "title": "AI fatigue is real and nobody talks about it | Siddhant Khare",
        "authors": "Siddhant Khare",
        "abstract": "You're using AI to be more productive. So why are you more exhausted than ever? The paradox every engineer needs to confront.",
        "timestamp": "2026-02-08T16:30:33.826Z",
        "rating": "novote",
        "publishedDate": "2026-02-08",
        "tags": [
          "Siddhant Khare",
          "AI agent infrastructure",
          "LLM agents",
          "agentic AI",
          "AI security",
          "OpenFGA",
          "CNCF",
          "memory systems",
          "authorization",
          "ReBAC",
          "agent orchestration",
          "context engineering",
          "context efficiency",
          "RAG deduplication",
          "KV-cache",
          "inference optimization",
          "software engineer",
          "open source",
          "Gitpod",
          "Ona",
          "machine learning infrastructure",
          "Zanzibar authorization",
          "distributed systems",
          "GPU profiling",
          "MCP servers"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 19,
        "object_id": "paper:url.64A41AB2",
        "created_at": "2026-02-08T16:30:34+00:00",
        "updated_at": "2026-02-08T16:30:53+00:00",
        "version": 1
      }
    },
    "paper:url.4F5694F4": {
      "data": {
        "sourceId": "url",
        "paperId": "4F5694F4",
        "url": "https://daplab.cs.columbia.edu/general/2026/01/07/why-vibe-coding-fails-and-how-to-fix-it.html",
        "title": "DAPLab - Data, Agents, and Processes | Columbia University",
        "authors": "DAPLab, Columbia University",
        "abstract": "A research lab at Columbia University working at the intersection of AI, systems, and automation.",
        "timestamp": "2026-02-08T16:30:05.829Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "DAPLab",
          "Columbia University",
          "agent-based systems",
          "systems research",
          "AI safety",
          "RL",
          "ML",
          "HCI",
          "cloud computing",
          "large language models",
          "trustworthy AI",
          "automation research",
          "operations research"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 18,
        "object_id": "paper:url.4F5694F4",
        "created_at": "2026-02-08T16:30:06+00:00",
        "updated_at": "2026-02-08T16:30:24+00:00",
        "version": 1
      }
    },
    "paper:url.7744C59C": {
      "data": {
        "sourceId": "url",
        "paperId": "7744C59C",
        "url": "https://aeon.co/videos/the-elaborate-places-ones-mind-wanders-in-solitary-confinement?utm_source=rss-feed",
        "title": "The elaborate places one\u2019s mind wanders in solitary confinement | Aeon Videos",
        "authors": "",
        "abstract": "Where does the mind go in solitary confinement? An evocative animation exploring three individual experiences",
        "timestamp": "2026-02-08T17:02:29.616Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 20,
        "object_id": "paper:url.7744C59C",
        "created_at": "2026-02-08T17:02:29+00:00",
        "updated_at": "2026-02-08T17:02:47+00:00",
        "version": 1
      }
    },
    "paper:url.214C1B64": {
      "data": {
        "sourceId": "url",
        "paperId": "214C1B64",
        "url": "https://ezhik.jp/ai-slop-terrifies-me/",
        "title": "(AI) Slop Terrifies Me \u2013 ezhik.jp",
        "authors": "",
        "abstract": "What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?",
        "timestamp": "2026-02-08T17:04:48.390Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 22,
        "object_id": "paper:url.214C1B64",
        "created_at": "2026-02-08T17:04:48+00:00",
        "updated_at": "2026-02-08T17:05:05+00:00",
        "version": 1
      }
    },
    "paper:url-misc.223BF1B6": {
      "data": {
        "sourceId": "url-misc",
        "paperId": "223BF1B6",
        "url": "https://pubmed.ncbi.nlm.nih.gov/41506004/",
        "title": "Blood omega-3 is inversely related to risk of early-onset dementia",
        "authors": "",
        "abstract": "This study expands the evidence of a beneficial association of omega-3 and LOD to EOD as well. These findings suggest that an increased intake of omega-3 fatty acids earlier in life may slow the development of EOD. Additional research is needed to confirm our findings, particularly in more diverse p \u2026",
        "timestamp": "2026-02-08T17:04:30.033Z",
        "rating": "novote",
        "publishedDate": "2026 Feb",
        "tags": [
          "pmid:41506004",
          "doi:10.1016/j.clnu.2025.106559",
          "Aleix Sala-Vila",
          "Nathan L Tintle",
          "William S Harris",
          "Adult",
          "Age of Onset",
          "Apolipoprotein E4 / genetics",
          "Cohort Studies",
          "Dementia* / blood",
          "Dementia* / epidemiology",
          "Dementia* / genetics",
          "Dementia* / prevention & control",
          "Diet* / statistics & numerical data",
          "Fatty Acids",
          "Omega-3* / blood",
          "Female",
          "Humans",
          "Male",
          "Middle Aged",
          "Proportional Hazards Models",
          "Risk Factors",
          "United Kingdom / epidemiology",
          "PubMed Abstract",
          "NIH",
          "NLM",
          "NCBI",
          "National Institutes of Health",
          "National Center for Biotechnology Information",
          "National Library of Medicine",
          "MEDLINE"
        ],
        "doi": "10.1016/j.clnu.2025.106559",
        "journalName": "Clinical nutrition (Edinburgh, Scotland)",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 21,
        "object_id": "paper:url-misc.223BF1B6",
        "created_at": "2026-02-08T17:04:30+00:00",
        "updated_at": "2026-02-08T17:04:50+00:00",
        "version": 1
      }
    },
    "paper:url.756E9B46": {
      "data": {
        "sourceId": "url",
        "paperId": "756E9B46",
        "url": "https://platform.claude.com/docs/en/agent-sdk/overview",
        "title": "Agent SDK overview",
        "authors": "",
        "abstract": "Build production AI agents with Claude Code as a library",
        "timestamp": "2026-02-08T21:33:07.955Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 23,
        "object_id": "paper:url.756E9B46",
        "created_at": "2026-02-08T21:33:08+00:00",
        "updated_at": "2026-02-08T21:33:27+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2408.08506": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2408.08506",
        "url": "https://arxiv.org/abs/2408.08506",
        "title": "Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding",
        "authors": "Lei Huang, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen",
        "abstract": "Generating long-term texts such as novels using artificial intelligence has always been a challenge. A common approach is to use large language models (LLMs) to construct a hierarchical framework that first plans and then writes. Despite the fact that the generated novels reach a sufficient length, they exhibit poor logical coherence and appeal in their plots and deficiencies in character and event depiction, ultimately compromising the overall narrative quality. In this paper, we propose a method named Extracting Excelsior and Expanding. Ex3 initially extracts structure information from raw novel data. By combining this structure information with the novel data, an instruction-following dataset is meticulously crafted. This dataset is then utilized to fine-tune the LLM, aiming for excelsior generation performance. In the final stage, a tree-like expansion method is deployed to facilitate the generation of arbitrarily long novels. Evaluation against previous methods showcases Ex3's ability to produce higher-quality long-form novels.",
        "timestamp": "2026-02-08T21:35:30.344Z",
        "rating": "novote",
        "publishedDate": "2024/08/16",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 24,
        "object_id": "paper:arxiv.2408.08506",
        "created_at": "2026-02-08T21:35:30+00:00",
        "updated_at": "2026-02-08T21:35:48+00:00",
        "version": 1
      }
    },
    "paper:openreview.H1ncX6O6Yh": {
      "data": {
        "sourceId": "openreview",
        "paperId": "H1ncX6O6Yh",
        "url": "https://openreview.net/forum?id=H1ncX6O6Yh",
        "title": "Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games",
        "authors": "",
        "abstract": "Large Language Model (LLM) agents are reshaping the game industry, by enabling more intelligent and human-preferable characters. Yet, current game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets to adapt pre-trained LLMs into gaming agents. To fill these gaps, we present Orak, a benchmark for training and evaluating LLM agents across 12 popular video games spanning all major genres. Using a plug-and-play interface built on Model Context Protocol (MCP), Orak supports systematic and reproducible studies of agentic modules in varied game scenarios. We further release a fine-tuning dataset of expert LLM gameplay trajectories spanning multiple genres, turning general LLMs into effective game agents. Orak offers a comprehensive evaluation framework, including game leaderboards, LLM battle arenas, and in-depth analyses of input modality, agentic strategies, and fine-tuning effects, establishing a foundation towards versatile gaming agents. Code is available at https://anonymous.4open.science/r/Orak-5013/.",
        "timestamp": "2026-02-08T22:18:39.325Z",
        "rating": "novote",
        "publishedDate": "26 Jan 2026",
        "tags": [
          "LLM",
          "Agents",
          "Benchmark",
          "Games"
        ],
        "doi": "",
        "journalName": "ICLR 2026 Poster",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 26,
        "object_id": "paper:openreview.H1ncX6O6Yh",
        "created_at": "2026-02-08T22:18:39+00:00",
        "updated_at": "2026-02-08T22:18:55+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2503.15655": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2503.15655",
        "url": "https://arxiv.org/abs/2503.15655",
        "title": "R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs",
        "authors": "Zefeng Lin, Yi Xiao, Zhiqiang Mo, Qifan Zhang, Jie Wang, Jiayang Chen, Jiajing Zhang, Hui Zhang, Zhengyi Liu, Xianyong Fang, Xiaohua Xu",
        "abstract": "Automatically adapting novels into screenplays is important for the TV, film, or opera industries to promote products with low costs. The strong performances of large language models (LLMs) in long-text generation call us to propose a LLM based framework Reader-Rewriter (R2^2) for this task. However, there are two fundamental challenges here. First, the LLM hallucinations may cause inconsistent plot extraction and screenplay generation. Second, the causality-embedded plot lines should be effectively extracted for coherent rewriting. Therefore, two corresponding tactics are proposed: 1) A hallucination-aware refinement method (HAR) to iteratively discover and eliminate the affections of hallucinations; and 2) a causal plot-graph construction method (CPC) based on a greedy cycle-breaking algorithm to efficiently construct plot lines with event causalities. Recruiting those efficient techniques, R2^2 utilizes two modules to mimic the human screenplay rewriting process: The Reader module adopts a sliding window and CPC to build the causal plot graphs, while the Rewriter module generates first the scene outlines based on the graphs and then the screenplays. HAR is integrated into both modules for accurate inferences of LLMs. Experimental results demonstrate the superiority of R2^2, which substantially outperforms three existing approaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison at the overall win rate for GPT-4o.",
        "timestamp": "2026-02-08T22:18:27.981Z",
        "rating": "novote",
        "publishedDate": "2025/03/19",
        "tags": [
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 25,
        "object_id": "paper:arxiv.2503.15655",
        "created_at": "2026-02-08T22:18:28+00:00",
        "updated_at": "2026-02-08T22:18:47+00:00",
        "version": 1
      }
    },
    "paper:url.46149ECF": {
      "data": {
        "sourceId": "url",
        "paperId": "46149ECF",
        "url": "https://www.theatlantic.com/ideas/2026/02/books-news-washington-post/685897/?utm_source=feed",
        "title": "The Literary Ecosystem Is Dying",
        "authors": "Adam Kirsch",
        "abstract": "In a sense, the decline of book reviews, like the decline of newspapers themselves, is a story about disaggregation.",
        "timestamp": "2026-02-09T00:23:17.078Z",
        "rating": "novote",
        "publishedDate": "2026-02-06T12:00:00Z",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 27,
        "object_id": "paper:url.46149ECF",
        "created_at": "2026-02-09T00:23:17+00:00",
        "updated_at": "2026-02-09T00:23:35+00:00",
        "version": 1
      }
    },
    "paper:url.2DB787B1": {
      "data": {
        "sourceId": "url",
        "paperId": "2DB787B1",
        "url": "https://odd-lots-books.netlify.app/",
        "title": "Odd Lots Books",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T02:09:07.679Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 28,
        "object_id": "paper:url.2DB787B1",
        "created_at": "2026-02-09T02:09:07+00:00",
        "updated_at": "2026-02-09T02:09:29+00:00",
        "version": 1
      }
    },
    "paper:url.35111C3C": {
      "data": {
        "sourceId": "url",
        "paperId": "35111C3C",
        "url": "https://github.com/yanaiela/service",
        "title": "yanaiela/service: library for different service automation",
        "authors": "",
        "abstract": "library for different service automation. Contribute to yanaiela/service development by creating an account on GitHub.",
        "timestamp": "2026-02-09T13:48:20.134Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 29,
        "object_id": "paper:url.35111C3C",
        "created_at": "2026-02-09T13:48:20+00:00",
        "updated_at": "2026-02-09T13:48:40+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.18866": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.18866",
        "url": "https://arxiv.org/abs/2510.18866",
        "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation",
        "authors": "Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao, Mengru Wang, Shuofei Qiao, Huajun Chen, Ningyu Zhang",
        "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at this https URL.",
        "timestamp": "2026-02-09T13:49:29.819Z",
        "rating": "novote",
        "publishedDate": "2025/10/21",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Computer Vision and Pattern Recognition (cs.CV)",
          "Machine Learning (cs.LG)",
          "Multiagent Systems (cs.MA)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 30,
        "object_id": "paper:arxiv.2510.18866",
        "created_at": "2026-02-09T13:49:30+00:00",
        "updated_at": "2026-02-09T13:49:52+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.10387": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2601.10387",
        "url": "https://arxiv.org/abs/2601.10387",
        "title": "The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models",
        "authors": "Christina Lu, Jack Gallagher, Jonathan Michala, Kyle Fish, Jack Lindsey",
        "abstract": "Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an \"Assistant Axis,\" which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts \"persona drift,\" a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona.",
        "timestamp": "2026-02-09T13:50:07.328Z",
        "rating": "novote",
        "publishedDate": "2026/01/15",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 31,
        "object_id": "paper:arxiv.2601.10387",
        "created_at": "2026-02-09T13:50:07+00:00",
        "updated_at": "2026-02-09T13:50:32+00:00",
        "version": 1
      }
    },
    "paper:url.6D0A3CDE": {
      "data": {
        "sourceId": "url",
        "paperId": "6D0A3CDE",
        "url": "https://hedgehogreview.com/web-features/thr/posts/a-mosaic",
        "title": "A Mosaic",
        "authors": "",
        "abstract": "I was looking for a hobby in prison but I found an education.",
        "timestamp": "2026-02-09T13:54:31.443Z",
        "rating": "novote",
        "publishedDate": "2026-01-08T11:59:00-05:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 32,
        "object_id": "paper:url.6D0A3CDE",
        "created_at": "2026-02-09T13:54:31+00:00",
        "updated_at": "2026-02-09T13:54:56+00:00",
        "version": 1
      }
    },
    "paper:url.220759C8": {
      "data": {
        "sourceId": "url",
        "paperId": "220759C8",
        "url": "https://www.interconnects.ai/p/opus-46-vs-codex-53?utm_campaign=email-half-post&r=4w5a66&utm_source=substack&utm_medium=email",
        "title": "Opus 4.6 vs. Codex 5.3",
        "authors": "Nathan Lambert",
        "abstract": "On comparing models in 2026.",
        "timestamp": "2026-02-09T14:08:30.745Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 33,
        "object_id": "paper:url.220759C8",
        "created_at": "2026-02-09T14:08:31+00:00",
        "updated_at": "2026-02-09T14:08:52+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2506.18841": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.18841",
        "url": "https://arxiv.org/abs/2506.18841",
        "title": "LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning",
        "authors": "Yuhao Wu, Yushi Bai, Zhiqiang Hu, Roy Ka-Wei Lee, Juanzi Li",
        "abstract": "Ultra-long generation by large language models (LLMs) is a widely demanded scenario, yet it remains a significant challenge due to their maximum generation length limit and overall quality degradation as sequence length increases. Previous approaches, exemplified by LongWriter, typically rely on ''teaching'', which involves supervised fine-tuning (SFT) on synthetic long-form outputs. However, this strategy heavily depends on synthetic SFT data, which is difficult and costly to construct, often lacks coherence and consistency, and tends to be overly artificial and structurally monotonous. In this work, we propose an incentivization-based approach that, starting entirely from scratch and without relying on any annotated or synthetic data, leverages reinforcement learning (RL) to foster the emergence of ultra-long, high-quality text generation capabilities in LLMs. We perform RL training starting from a base model, similar to R1-Zero, guiding it to engage in reasoning that facilitates planning and refinement during the writing process. To support this, we employ specialized reward models that steer the LLM towards improved length control, writing quality, and structural formatting. Experimental evaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B, consistently outperforms traditional SFT methods on long-form writing tasks, achieving state-of-the-art results across all metrics on WritingBench and Arena-Write, and even surpassing 100B+ models such as DeepSeek R1 and Qwen3-235B. We open-source our data and model checkpoints under this https URL",
        "timestamp": "2026-02-09T15:15:17.616Z",
        "rating": "novote",
        "publishedDate": "2025/06/23",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 34,
        "object_id": "paper:arxiv.2506.18841",
        "created_at": "2026-02-09T15:15:17+00:00",
        "updated_at": "2026-02-09T15:15:40+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.04811": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.04811",
        "url": "https://arxiv.org/abs/2602.04811",
        "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization",
        "authors": "Jiarui Yuan, Tailin Jin, Weize Chen, Zeyuan Liu, Zhiyuan Liu, Maosong Sun",
        "abstract": "True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring \"Closed-Book Training\" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at this https URL.",
        "timestamp": "2026-02-09T15:19:20.169Z",
        "rating": "novote",
        "publishedDate": "2026/02/04",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 36,
        "object_id": "paper:arxiv.2602.04811",
        "created_at": "2026-02-09T15:19:20+00:00",
        "updated_at": "2026-02-09T15:19:41+00:00",
        "version": 1
      }
    },
    "paper:url-misc.68D79817": {
      "data": {
        "sourceId": "url-misc",
        "paperId": "68D79817",
        "url": "https://aleximas.substack.com/p/someday-we-will-all-be-artists",
        "title": "Someday we will all be artists",
        "authors": "Alex Imas",
        "abstract": "How AI will change the nature of work and art",
        "timestamp": "2026-02-09T15:18:48.370Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 35,
        "object_id": "paper:url-misc.68D79817",
        "created_at": "2026-02-09T15:18:48+00:00",
        "updated_at": "2026-02-09T15:19:11+00:00",
        "version": 1
      }
    },
    "paper:url.6F62DF27": {
      "data": {
        "sourceId": "url",
        "paperId": "6F62DF27",
        "url": "https://huggingface.co/opendatalab/PDF-Extract-Kit-1.0",
        "title": "opendatalab/PDF-Extract-Kit-1.0 \u00b7 Hugging Face",
        "authors": "",
        "abstract": "We\u2019re on a journey to advance and democratize artificial intelligence through open source and open science.",
        "timestamp": "2026-02-09T15:51:48.576Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 37,
        "object_id": "paper:url.6F62DF27",
        "created_at": "2026-02-09T15:51:48+00:00",
        "updated_at": "2026-02-09T15:52:08+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2501.18099": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2501.18099",
        "url": "https://arxiv.org/abs/2501.18099",
        "title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge",
        "authors": "Swarnadeep Saha, Xian Li, Marjan Ghazvininejad, Jason Weston, Tianlu Wang",
        "abstract": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to capture the step-bystep reasoning process that underlies the final evaluation of a response. However, due to the lack of human annotated CoTs for evaluation, the required components and structure of effective reasoning traces remain understudied. Consequently, previous approaches often (1) constrain reasoning traces to hand-designed components, such as a list of criteria, reference answers, or verification questions and (2) structure them such that planning is intertwined with the reasoning for evaluation. In this work, we propose EvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge that first generates an unconstrained evaluation plan, followed by its execution, and then the final judgment. In a self-training loop, EvalPlanner iteratively optimizes over synthetically constructed evaluation plans and executions, leading to better final verdicts. Our method achieves a new state-of-the-art performance for generative reward models on RewardBench (with a score of 93.9), despite being trained on fewer amount of, and synthetically generated, preference pairs. Additional experiments on other benchmarks like RM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both planning and reasoning for building robust LLM-as-a-Judge reasoning models.",
        "timestamp": "2026-02-09T17:57:24.729Z",
        "rating": "novote",
        "publishedDate": "2025/01/30",
        "tags": [
          "Artificial Intelligence (cs.AI)",
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 40,
        "object_id": "paper:arxiv.2501.18099",
        "created_at": "2026-02-09T17:57:24+00:00",
        "updated_at": "2026-02-09T17:57:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.11900": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2504.11900",
        "url": "https://arxiv.org/abs/2504.11900",
        "title": "Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models via Plot Hole Detection",
        "authors": "Kabir Ahuja, Melanie Sclar, Yulia Tsvetkov",
        "abstract": "Stories are a fundamental aspect of human experience. Engaging deeply with stories and spotting plot holes -- inconsistencies in a storyline that break the internal logic or rules of a story's world -- requires nuanced reasoning skills, including tracking entities and events and their interplay, abstract thinking, pragmatic narrative understanding, commonsense and social reasoning, and theory of mind. As Large Language Models (LLMs) increasingly generate, interpret, and modify text, rigorously assessing their narrative consistency and deeper language understanding becomes critical. However, existing benchmarks focus mainly on surface-level comprehension. In this work, we propose plot hole detection in stories as a proxy to evaluate language understanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel algorithm to controllably and carefully synthesize plot holes in human-written stories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot hole detection abilities in stories -- FlawedFictions -- , which is robust to contamination, with human filtering ensuring high quality. We find that state-of-the-art LLMs struggle in accurately solving FlawedFictions regardless of the reasoning effort allowed, with performance significantly degrading as story length increases. Finally, we show that LLM-based story summarization and story generation are prone to introducing plot holes, with more than 50% and 100% increases in plot hole detection rates with respect to human-written originals.",
        "timestamp": "2026-02-09T18:33:04.122Z",
        "rating": "novote",
        "publishedDate": "2025/04/16",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 41,
        "object_id": "paper:arxiv.2504.11900",
        "created_at": "2026-02-09T18:33:04+00:00",
        "updated_at": "2026-02-09T18:33:26+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.11868": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2601.11868",
        "url": "https://arxiv.org/abs/2601.11868",
        "title": "Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces",
        "authors": "Mike A. Merrill, Alexander G. Shaw, Nicholas Carlini, Boxuan Li, Harsh Raj, Ivan Bercovich, Lin Shi, Jeong Yeon Shin, Thomas Walshe, E. Kelly Buchanan, Junhong Shen, Guanghao Ye, Haowei Lin, Jason Poulos, Maoyu Wang, Marianna Nezhurina, Jenia Jitsev, Di Lu, Orfeas Menis Mastromichalakis, Zhiwei Xu, Zizhao Chen, Yue Liu, Robert Zhang, Leon Liangyu Chen, Anurag Kashyap, Jan-Lucas Uslu, Jeffrey Li, Jianbo Wu, Minghao Yan, Song Bian, Vedang Sharma, Ke Sun, Steven Dillmann, Akshay Anand, Andrew Lanpouthakoun, Bardia Koopah, Changran Hu, Etash Guha, Gabriel H. S. Dreiman, Jiacheng Zhu, Karl Krauth, Li Zhong, Niklas Muennighoff, Robert Amanfu, Shangyin Tan, Shreyas Pimpalgaonkar, Tushar Aggarwal, Xiangning Lin, Xin Lan, Xuandong Zhao, Yiqing Liang, Yuanli Wang, Zilong Wang, Changzhi Zhou, David Heineman, Hange Liu, Harsh Trivedi, John Yang, Junhong Lin, Manish Shetty, Michael Yang, Nabil Omi, Negin Raoof, Shanda Li, Terry Yue Zhuo, Wuwei Lin, Yiwei Dai, Yuxin Wang, Wenhao Chai, Shang Zhou, Dariush Wahdany, Ziyu She, Jiaming Hu, Zhikang Dong, Yuxuan Zhu, Sasha Cui, Ahson Saiyed, Arinbj\u00f6rn Kolbeinsson, Jesse Hu, Christopher Michael Rytting, Ryan Marten, Yixin Wang, Alex Dimakis, Andy Konwinski, Ludwig Schmidt",
        "abstract": "AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at this https URL .",
        "timestamp": "2026-02-09T20:53:37.369Z",
        "rating": "novote",
        "publishedDate": "2026/01/17",
        "tags": [
          "Software Engineering (cs.SE)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 43,
        "object_id": "paper:arxiv.2601.11868",
        "created_at": "2026-02-09T20:53:37+00:00",
        "updated_at": "2026-02-09T20:53:57+00:00",
        "version": 1
      }
    },
    "paper:url.26DA80ED": {
      "data": {
        "sourceId": "url",
        "paperId": "26DA80ED",
        "url": "https://anthology.ach.org/",
        "title": "Anthology of Computers and the Humanities",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T20:56:26.187Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 44,
        "object_id": "paper:url.26DA80ED",
        "created_at": "2026-02-09T20:56:26+00:00",
        "updated_at": "2026-02-09T20:57:13+00:00",
        "version": 1
      }
    },
    "paper:url.5DD06E7F": {
      "data": {
        "sourceId": "url",
        "paperId": "5DD06E7F",
        "url": "https://anthology.ach.org/volumes/vol0003/cultural-collapse-toward-generative-formalism-for/",
        "title": "Cultural Collapse: Toward a Generative Formalism for AI Cultural\nProduction",
        "authors": "Heuser, Ryan",
        "abstract": "This paper examines systematic patterns of idealization in large\nlanguage model outputs through computational analysis of over 15,000\nAI-generated poems and artificial bibliographic data. The study reveals\nand theorizes \u2018cultural collapse\u2019\u2014the tendency of LLMs to generate\ncultural content that is more formulaic and idealized than can be\nobserved in any historical period. Analysis of rhyme patterns shows that\nmodels produce formally conservative verse at rates that exceed even the\nmost traditional historical periods. This bias persists even when models\nare explicitly instructed against traditional forms and cannot be\nexplained by training data composition, suggesting deep computational\ntendencies toward idealization. Extending beyond poetics, parallel\npatterns emerge in historical domains: when prompted to generate\nhistorical publication data, models systematically produce demographic\ndistributions that obscure well-known exclusion patterns, creating\nrevisionist narratives where marginalized authors were published at\nrates far exceeding historical reality. The study identifies instruction\ntuning as one contributing mechanism, with models fine-tuned to be\nhelpful assistants showing significantly greater \u2018idealization\u2019 than\nbase models. These findings suggest that cultural collapse operates\nthrough a computational logic that privileges satisfaction over\nfrustration, regularity over variation, and conformity over\ncontradiction. As generative systems become ubiquitous in cultural\nproduction, their idealizing tendencies threaten to flatten cultural\ndiversity and historical complexity, requiring new critical frameworks\nfor understanding computational mediation of cultural transmission.",
        "timestamp": "2026-02-09T20:58:08.450Z",
        "rating": "novote",
        "publishedDate": "2025",
        "tags": [],
        "doi": "10.63744/USvuyzSIapvy",
        "journalName": "Anthology of Computers and the Humanities",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 45,
        "object_id": "paper:url.5DD06E7F",
        "created_at": "2026-02-09T20:58:08+00:00",
        "updated_at": "2026-02-09T20:58:31+00:00",
        "version": 1
      }
    },
    "paper:url.6D647947": {
      "data": {
        "sourceId": "url",
        "paperId": "6D647947",
        "url": "https://techxplore.com/news/2018-09-behavior-goodreads-amazon-bestsellers.html",
        "title": "Analyzing book reading behavior on Goodreads to predict Amazon Bestsellers",
        "authors": "",
        "abstract": "Researchers at Northwestern University, Microsoft Research India, and the Indian Institute of Technology Kharagpur have recently developed a model to predict whether a book will become a bestseller on Amazon within 15 days of its publication. Their model, outlined in a study pre-published on arXiv, works by analyzing reading behavior on the online platform Goodreads.",
        "timestamp": "2026-02-09T21:13:48.739Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "hi-tech news",
          "hitech",
          "innovation",
          "inventions",
          "computer news",
          "information technology"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 47,
        "object_id": "paper:url.6D647947",
        "created_at": "2026-02-09T21:13:49+00:00",
        "updated_at": "2026-02-09T21:14:12+00:00",
        "version": 1
      }
    },
    "paper:url.30331C8C": {
      "data": {
        "sourceId": "url",
        "paperId": "30331C8C",
        "url": "https://www.semanticscholar.org/paper/Who-decides-what-is-read-on-Goodreads-Uncovering-Hu-Diesner/4f53942e0621d172ae60ec090ecd76fc012fb6f8",
        "title": "The Goodreads \u201cClassics\u201d: A Computational Study of Readers, Amazon, and Crowdsourced Amateur Criticism",
        "authors": "Melanie Walsh, Maria Antoniak",
        "abstract": "The scale of the phenomena of incentivized book reviews is revealed for the first time, which illuminates the rise of sponsored content while contributing to broader discussions on computational approaches to digital economies of prestige and the responsible use of platform-mediated cultural datasets across disciplines. Attracted by the promise of a broader and more egalitarian sample of readers than published book reviews provide, researchers are increasingly scraping social reviewing platforms like Goodreads for data about readers\u2019 behavior. Yet, treating online book reviews as direct proxies for readers and books can be problematic, as they are socially and technically constructed artifacts shaped by platform dynamics, whether between developers and users, or book industry stakeholders and reviewers. To uncover these complexities, we computationally curated 331,211 self-identified incentivized book reviews to understand the growth of incentivized content, and how these purportedly equal-access social reviewing spaces are re-inscribing the inequalities of traditional book reviewing and publishing. Our findings underscore the necessity of critical examination of both online book reviewing and cultural datasets derived from social media platforms. With the growing restrictions on access to platform data for research, this study also demonstrates the potential for a mixed-method analysis of historical scraped datasets; an approach that will likely be of interest to many researchers working with cultural data moderated by black-box algorithms. With this method, our research reveals for the first time the scale of the phenomena of incentivized book reviews that is well known to users of Goodreads but remains largely anecdotal. Additionally, it illuminates the rise of sponsored content while contributing to broader discussions on computational approaches to digital economies of prestige and the responsible use of platform-mediated cultural datasets across disciplines.",
        "timestamp": "2026-02-09T21:13:37.301Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "Journal of Cultural Analytics",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 46,
        "object_id": "paper:url.30331C8C",
        "created_at": "2026-02-09T21:13:37+00:00",
        "updated_at": "2026-02-09T21:13:59+00:00",
        "version": 1
      }
    },
    "paper:url.64A6F94C": {
      "data": {
        "sourceId": "url",
        "paperId": "64A6F94C",
        "url": "https://www.publishersweekly.com/pw/by-topic/digital/copyright/article/99019-new-report-examines-writers-attitudes-toward-ai.html",
        "title": "New Report Examines Writers\u2019 Attitudes toward AI",
        "authors": "",
        "abstract": "A study commissioned by the Gotham Ghostwriters and Bernoff.com found that while 61% of professional writers are embracing AI tools, authors, specifically fiction authors, are much more wary.",
        "timestamp": "2026-02-09T21:16:19.122Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "Gotham Ghostwriters",
          "Josh Bernoff",
          "AI",
          "Chat GPT"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 50,
        "object_id": "paper:url.64A6F94C",
        "created_at": "2026-02-09T21:16:19+00:00",
        "updated_at": "2026-02-09T21:16:39+00:00",
        "version": 1
      }
    },
    "paper:url.1EB56418": {
      "data": {
        "sourceId": "url",
        "paperId": "1EB56418",
        "url": "https://insights.bookbub.com/how-authors-are-thinking-about-ai-survey/",
        "title": "How Authors Are Thinking About AI (Survey of 1,200+ Authors)",
        "authors": "Carlyn Robertson",
        "abstract": "We surveyed more than 1,200 authors to learn how they're thinking about generative AI as it relates to their work. Here's what they had to say.",
        "timestamp": "2026-02-09T21:16:09.683Z",
        "rating": "novote",
        "publishedDate": "2025-05-15T13:04:25+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 49,
        "object_id": "paper:url.1EB56418",
        "created_at": "2026-02-09T21:16:09+00:00",
        "updated_at": "2026-02-09T21:16:29+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.09747": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.09747",
        "url": "https://arxiv.org/abs/2502.09747",
        "title": "The Widespread Adoption of Large Language Model-Assisted Writing Across Society",
        "authors": "Weixin Liang, Yaohui Zhang, Mihai Codreanu, Jiayu Wang, Hancheng Cao, James Zou",
        "abstract": "The recent advances in large language models (LLMs) attracted significant public and policymaker interest in its adoption patterns. In this paper, we systematically analyze LLM-assisted writing across four domains-consumer complaints, corporate communications, job postings, and international organization press releases-from January 2022 to September 2024. Our dataset includes 687,241 consumer complaints, 537,413 corporate press releases, 304.3 million job postings, and 15,919 United Nations (UN) press releases. Using a robust population-level statistical framework, we find that LLM usage surged following the release of ChatGPT in November 2022. By late 2024, roughly 18% of financial consumer complaint text appears to be LLM-assisted, with adoption patterns spread broadly across regions and slightly higher in urban areas. For corporate press releases, up to 24% of the text is attributable to LLMs. In job postings, LLM-assisted writing accounts for just below 10% in small firms, and is even more common among younger firms. UN press releases also reflect this trend, with nearly 14% of content being generated or modified by LLMs. Although adoption climbed rapidly post-ChatGPT, growth appears to have stabilized by 2024, reflecting either saturation in LLM adoption or increasing subtlety of more advanced models. Our study shows the emergence of a new reality in which firms, consumers and even international organizations substantially rely on generative AI for communications.",
        "timestamp": "2026-02-09T21:15:40.332Z",
        "rating": "novote",
        "publishedDate": "2025/02/13",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 48,
        "object_id": "paper:arxiv.2502.09747",
        "created_at": "2026-02-09T21:15:40+00:00",
        "updated_at": "2026-02-09T21:16:04+00:00",
        "version": 1
      }
    },
    "paper:url.114087CA": {
      "data": {
        "sourceId": "url",
        "paperId": "114087CA",
        "url": "https://www.bookautoai.com/",
        "title": "The #1 Non-Fiction Writer",
        "authors": "",
        "abstract": "Turn your ideas into a masterpiece\u2014humanized, polished, and platform-ready. Let BookAutoAI bring your story to life!",
        "timestamp": "2026-02-09T21:21:07.790Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 51,
        "object_id": "paper:url.114087CA",
        "created_at": "2026-02-09T21:21:08+00:00",
        "updated_at": "2026-02-09T21:21:29+00:00",
        "version": 1
      }
    },
    "paper:url.6A293AC6": {
      "data": {
        "sourceId": "url",
        "paperId": "6A293AC6",
        "url": "https://lostbooks.ca/",
        "title": "Lost Books \u2013 AI-Assisted Dystopian Sci-Fi by Tim Boucher",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T21:25:33.178Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 52,
        "object_id": "paper:url.6A293AC6",
        "created_at": "2026-02-09T21:25:33+00:00",
        "updated_at": "2026-02-09T21:25:51+00:00",
        "version": 1
      }
    },
    "paper:url.7274CFA9": {
      "data": {
        "sourceId": "url",
        "paperId": "7274CFA9",
        "url": "https://www.newsweek.com/ai-books-art-money-artificial-intelligence-1799923",
        "title": "\"I'm making thousands using AI to write books\"",
        "authors": "",
        "abstract": "This approach has been successful. I have an unprecedented rate of production.",
        "timestamp": "2026-02-09T21:26:25.796Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 53,
        "object_id": "paper:url.7274CFA9",
        "created_at": "2026-02-09T21:26:26+00:00",
        "updated_at": "2026-02-09T21:26:48+00:00",
        "version": 1
      }
    },
    "paper:url.2F912D55": {
      "data": {
        "sourceId": "url",
        "paperId": "2F912D55",
        "url": "https://www.publicbooks.org/defending-the-possibility-of-the-university-a-roundtable-on-university-keywords/",
        "title": "Defending the Possibility of the University: A Roundtable on \u201cUniversity Keywords\u201d - Public Books",
        "authors": "Megan Cummins",
        "abstract": "\u201cWhat would it look like for faculty unions and graduate student unions to collaborate or work together with K-12 teachers\u2019 unions to push back against anti-DEI legislation or book bans?\u201d",
        "timestamp": "2026-02-09T21:28:30.011Z",
        "rating": "novote",
        "publishedDate": "2026-02-04T16:00:00+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 54,
        "object_id": "paper:url.2F912D55",
        "created_at": "2026-02-09T21:28:30+00:00",
        "updated_at": "2026-02-09T21:28:53+00:00",
        "version": 1
      }
    },
    "paper:url.1EA16CE": {
      "data": {
        "sourceId": "url",
        "paperId": "1EA16CE",
        "url": "https://www.publicbooks.org/how-translations-sell-three-u-s-eras-of-international-bestsellers/",
        "title": "How Translations Sell: Three U.S. Eras of International Bestsellers - Public Books",
        "authors": "Megan Cummins",
        "abstract": "A translation renaissance in US publishing just ended. And you probably missed it.",
        "timestamp": "2026-02-09T21:30:06.854Z",
        "rating": "novote",
        "publishedDate": "2025-09-16T15:00:31+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 56,
        "object_id": "paper:url.1EA16CE",
        "created_at": "2026-02-09T21:30:07+00:00",
        "updated_at": "2026-02-09T21:30:44+00:00",
        "version": 1
      }
    },
    "paper:url.5BC116CB": {
      "data": {
        "sourceId": "url",
        "paperId": "5BC116CB",
        "url": "https://www.publicbooks.org/on-our-nightstands-september-2023/",
        "title": "On Our Nightstands: September 2023 - Public Books",
        "authors": "Imani Radney",
        "abstract": "A behind-the-scenes look at what \u201cPublic Books\u201d editors and staff have been reading this month.",
        "timestamp": "2026-02-09T21:29:53.905Z",
        "rating": "novote",
        "publishedDate": "2023-09-08T15:00:33+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 55,
        "object_id": "paper:url.5BC116CB",
        "created_at": "2026-02-09T21:29:54+00:00",
        "updated_at": "2026-02-09T21:30:15+00:00",
        "version": 1
      }
    },
    "paper:url.3240606D": {
      "data": {
        "sourceId": "url",
        "paperId": "3240606D",
        "url": "https://billieleelucas.medium.com/how-i-made-73-dollars-with-amazon-kdp-today-a-full-bookautoai-review-8b14c810f9fd",
        "title": "How I Made $73 Dollars With Amazon KDP Today |a Full BookAutoAI Review",
        "authors": "Billie Lee Lucas",
        "abstract": "How I Made $73 Dollars With Amazon KDP Today | a Full BookAutoAI Review I made $73 today so far. I know it\u2019s less than the hundreds I\u2019ve shown before, but this is another one of my accounts that \u2026",
        "timestamp": "2026-02-09T21:31:28.298Z",
        "rating": "novote",
        "publishedDate": "2025-09-25T04:15:17.390Z",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 57,
        "object_id": "paper:url.3240606D",
        "created_at": "2026-02-09T21:31:28+00:00",
        "updated_at": "2026-02-09T21:31:48+00:00",
        "version": 1
      }
    },
    "paper:url.5977F244": {
      "data": {
        "sourceId": "url",
        "paperId": "5977F244",
        "url": "https://www.goodreads.com/list/show/219041.Books_I_Have_No_Doubt_Are_Written_By_A_I_",
        "title": "Books I Have No Doubt Are Written By A.I. (97 books) | Goodreads",
        "authors": "",
        "abstract": "97 books based on 9 votes: Elven Blood by Mark Stanley, Battle Mage (Volume 2 of the Vellhor Saga): A Fantasy Realms Novel by Mark Stanley, Dwarven Princ...",
        "timestamp": "2026-02-09T21:33:56.785Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 59,
        "object_id": "paper:url.5977F244",
        "created_at": "2026-02-09T21:33:57+00:00",
        "updated_at": "2026-02-09T21:34:20+00:00",
        "version": 1
      }
    },
    "paper:url.5F9A774A": {
      "data": {
        "sourceId": "url",
        "paperId": "5F9A774A",
        "url": "https://www.goodreads.com/list/tag/ai-book",
        "title": "Ai Book Book Lists | Goodreads",
        "authors": "",
        "abstract": "Lists about: Books I Have No Doubt Are Written By A.I., Undoubtedly an AI book, ChatGPT AI cover art , AI books published in October 2025, Yes, AI slop i...",
        "timestamp": "2026-02-09T21:33:43.554Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 58,
        "object_id": "paper:url.5F9A774A",
        "created_at": "2026-02-09T21:33:43+00:00",
        "updated_at": "2026-02-09T21:34:04+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2503.14499": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2503.14499",
        "url": "https://arxiv.org/abs/2503.14499",
        "title": "Measuring AI Ability to Complete Long Tasks",
        "authors": "Thomas Kwa, Ben West, Joel Becker, Amy Deng, Katharyn Garcia, Max Hasin, Sami Jawhar, Megan Kinniment, Nate Rush, Sydney Von Arx, Ryan Bloom, Thomas Broadley, Haoxing Du, Brian Goodrich, Nikola Jurkovic, Luke Harold Miles, Seraphina Nix, Tao Lin, Neev Parikh, David Rein, Lucas Jun Koba Sato, Hjalmar Wijk, Daniel M. Ziegler, Elizabeth Barnes, Lawrence Chan",
        "abstract": "Despite rapid progress on AI benchmarks, the real-world meaning of benchmark performance remains unclear. To quantify the capabilities of AI systems in terms of human capabilities, we propose a new metric: 50%-task-completion time horizon. This is the time humans typically take to complete tasks that AI models can complete with 50% success rate. We first timed humans with relevant domain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter tasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet have a 50% time horizon of around 50 minutes. Furthermore, frontier AI time horizon has been doubling approximately every seven months since 2019, though the trend may have accelerated in 2024. The increase in AI models' time horizons seems to be primarily driven by greater reliability and ability to adapt to mistakes, combined with better logical reasoning and tool use capabilities. We discuss the limitations of our results -- including their degree of external validity -- and the implications of increased autonomy for dangerous capabilities. If these results generalize to real-world software tasks, extrapolation of this trend predicts that within 5 years, AI systems will be capable of automating many software tasks that currently take humans a month.",
        "timestamp": "2026-02-09T21:54:25.085Z",
        "rating": "novote",
        "publishedDate": "2025/03/18",
        "tags": [
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 60,
        "object_id": "paper:arxiv.2503.14499",
        "created_at": "2026-02-09T21:54:25+00:00",
        "updated_at": "2026-02-09T21:54:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2505.13400": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2505.13400",
        "url": "https://arxiv.org/abs/2505.13400",
        "title": "Robin: A multi-agent system for automating scientific discovery",
        "authors": "Ali Essam Ghareeb, Benjamin Chang, Ludovico Mitchener, Angela Yiu, Caralyn J. Szostkiewicz, Jon M. Laurent, Muhammed T. Razzak, Andrew D. White, Michaela M. Hinks, Samuel G. Rodriques",
        "abstract": "Scientific discovery is driven by the iterative process of background research, hypothesis generation, experimentation, and data analysis. Despite recent advancements in applying artificial intelligence to scientific discovery, no system has yet automated all of these stages in a single workflow. Here, we introduce Robin, the first multi-agent system capable of fully automating the key intellectual steps of the scientific process. By integrating literature search agents with data analysis agents, Robin can generate hypotheses, propose experiments, interpret experimental results, and generate updated hypotheses, achieving a semi-autonomous approach to scientific discovery. By applying this system, we were able to identify a novel treatment for dry age-related macular degeneration (dAMD), the major cause of blindness in the developed world. Robin proposed enhancing retinal pigment epithelium phagocytosis as a therapeutic strategy, and identified and validated a promising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho kinase (ROCK) inhibitor that has never previously been proposed for treating dAMD. To elucidate the mechanism of ripasudil-induced upregulation of phagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment, which revealed upregulation of ABCA1, a critical lipid efflux pump and possible novel target. All hypotheses, experimental plans, data analyses, and data figures in the main text of this report were produced by Robin. As the first AI system to autonomously discover and validate a novel therapeutic candidate within an iterative lab-in-the-loop framework, Robin establishes a new paradigm for AI-driven scientific discovery.",
        "timestamp": "2026-02-09T21:55:47.573Z",
        "rating": "novote",
        "publishedDate": "2025/05/19",
        "tags": [
          "Artificial Intelligence (cs.AI)",
          "Multiagent Systems (cs.MA)",
          "Quantitative Methods (q-bio.QM)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 61,
        "object_id": "paper:arxiv.2505.13400",
        "created_at": "2026-02-09T21:55:47+00:00",
        "updated_at": "2026-02-09T21:56:18+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2509.19163": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2509.19163",
        "url": "https://arxiv.org/abs/2509.19163",
        "title": "Measuring AI \"Slop\" in Text",
        "authors": "Chantal Shaib, Tuhin Chakrabarty, Diego Garcia-Olano, Byron C. Wallace",
        "abstract": "AI \"slop\" is an increasingly popular term used to describe low-quality AI-generated text, but there is currently no agreed upon definition of this term nor a means to measure its occurrence. In this work, we develop a taxonomy of \"slop\" through interviews with experts in NLP, writing, and philosophy, and propose a set of interpretable dimensions for its assessment in text. Through span-level annotation, we find that binary \"slop\" judgments are (somewhat) subjective, but such determinations nonetheless correlate with latent dimensions such as coherence and relevance. Our framework can be used to evaluate AI-generated text in both detection and binary preference tasks, potentially offering new insights into the linguistic and stylistic factors that contribute to quality judgments.",
        "timestamp": "2026-02-09T22:00:19.365Z",
        "rating": "novote",
        "publishedDate": "2025/09/23",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 62,
        "object_id": "paper:arxiv.2509.19163",
        "created_at": "2026-02-09T22:00:19+00:00",
        "updated_at": "2026-02-09T22:00:51+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.06176": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.06176",
        "url": "https://arxiv.org/abs/2602.06176",
        "title": "Large Language Model Reasoning Failures",
        "authors": "Peiyang Song, Pengrui Han, Noah Goodman",
        "abstract": "Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distinguishes reasoning into embodied and non-embodied types, with the latter further subdivided into informal (intuitive) and formal (logical) reasoning. In parallel, we classify reasoning failures along a complementary axis into three types: fundamental failures intrinsic to LLM architectures that broadly affect downstream tasks; application-specific limitations that manifest in particular domains; and robustness issues characterized by inconsistent performance across minor variations. For each reasoning failure, we provide a clear definition, analyze existing studies, explore root causes, and present mitigation strategies. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities. We additionally release a comprehensive collection of research works on LLM reasoning failures, as a GitHub repository at this https URL, to provide an easy entry point to this area.",
        "timestamp": "2026-02-09T17:00:59.850Z",
        "rating": "novote",
        "publishedDate": "2026/02/05",
        "tags": [
          "Artificial Intelligence (cs.AI)",
          "Computation and Language (cs.CL)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 39,
        "object_id": "paper:arxiv.2602.06176",
        "created_at": "2026-02-09T17:01:00+00:00",
        "updated_at": "2026-02-09T22:10:14+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2511.19399": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2511.19399",
        "url": "https://arxiv.org/abs/2511.19399",
        "title": "DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research",
        "authors": "Rulin Shao, Akari Asai, Shannon Zejiang Shen, Hamish Ivison, Varsha Kishore, Jingming Zhuo, Xinran Zhao, Molly Park, Samuel G. Finlayson, David Sontag, Tyler Murray, Sewon Min, Pradeep Dasigi, Luca Soldaini, Faeze Brahman, Wen-tau Yih, Tongshuang Wu, Luke Zettlemoyer, Yoon Kim, Hannaneh Hajishirzi, Pang Wei Koh",
        "abstract": "Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.",
        "timestamp": "2026-02-09T16:43:29.692Z",
        "rating": "novote",
        "publishedDate": "2025/11/24",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 38,
        "object_id": "paper:arxiv.2511.19399",
        "created_at": "2026-02-09T16:43:30+00:00",
        "updated_at": "2026-02-09T22:10:19+00:00",
        "version": 1
      }
    },
    "paper:url.153C303C": {
      "data": {
        "sourceId": "url",
        "paperId": "153C303C",
        "url": "https://github.com/laude-institute/harbor",
        "title": "laude-institute/harbor: Harbor is a framework for running agent evaluations and creating and using RL environments.",
        "authors": "",
        "abstract": "Harbor is a framework for running agent evaluations and creating and using RL environments. - laude-institute/harbor",
        "timestamp": "2026-02-09T22:13:33.962Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 63,
        "object_id": "paper:url.153C303C",
        "created_at": "2026-02-09T22:13:34+00:00",
        "updated_at": "2026-02-09T22:13:58+00:00",
        "version": 1
      }
    },
    "paper:url.541DE607": {
      "data": {
        "sourceId": "url",
        "paperId": "541DE607",
        "url": "https://www.swebench.com/",
        "title": "SWE-bench Leaderboards",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T22:41:32.502Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 64,
        "object_id": "paper:url.541DE607",
        "created_at": "2026-02-09T22:41:32+00:00",
        "updated_at": "2026-02-09T22:41:55+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.06855": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.06855",
        "url": "https://arxiv.org/abs/2602.06855",
        "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
        "authors": "Alisia Lupidi, Bhavul Gauri, Thomas Simon Foster, Bassel Al Omari, Despoina Magka, Alberto Pepe, Alexis Audran-Reiss, Muna Aghamelu, Nicolas Baldwin, Lucia Cipolina-Kun, Jean-Christophe Gagnon-Audet, Chee Hau Leow, Sandra Lefdal, Hossam Mossalam, Abhinav Moudgil, Saba Nazir, Emanuel Tewolde, Isabel Urrego, Jordi Armengol Estape, Amar Budhiraja, Gaurav Chaurasia, Abhishek Charnalia, Derek Dunfield, Karen Hambardzumyan, Daniel Izcovich, Martin Josifoski, Ishita Mediratta, Kelvin Niu, Parth Pathak, Michael Shvartsman, Edan Toledo, Anton Protopopov, Roberta Raileanu, Alexander Miller, Tatiana Shavrina, Jakob Foerster, Yoram Bachrach",
        "abstract": "LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds. Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.",
        "timestamp": "2026-02-09T23:41:11.339Z",
        "rating": "novote",
        "publishedDate": "2026/02/06",
        "tags": [
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 65,
        "object_id": "paper:arxiv.2602.06855",
        "created_at": "2026-02-09T23:41:11+00:00",
        "updated_at": "2026-02-09T23:41:44+00:00",
        "version": 1
      }
    },
    "paper:openreview.Q6PAnqYVpo": {
      "data": {
        "sourceId": "openreview",
        "paperId": "Q6PAnqYVpo",
        "url": "https://openreview.net/forum?id=Q6PAnqYVpo",
        "title": "SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus Searches",
        "authors": "Hiroyuki Deguchi, Go Kamoda, Yusuke Matsushita, Chihiro Taguchi, Kohei Suenaga, Masaki Waga, Sho Yokoi",
        "abstract": "Researchers and practitioners in natural language processing and computational linguistics frequently observe and analyze the real language usage in large-scale corpora.\nFor that purpose, they often employ off-the-shelf pattern-matching tools, such as grep, and keyword-in-context concordancers, which is widely used in corpus linguistics for gathering examples.\nNonetheless, these existing techniques rely on surface-level string matching, and thus they suffer from the major limitation of not being able to handle orthographic variations and paraphrasing---notable and common phenomena in any natural language.\nIn addition, existing continuous approaches such as dense vector search tend to be overly coarse, often retrieving texts that are unrelated but share similar topics.\nGiven these challenges, we propose a novel algorithm that achieves soft (or semantic) yet efficient pattern matching by relaxing a surface-level matching with word embeddings.\nOur algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.\nWe have prepared an efficient implementation, and we provide an accessible web tool.\nOur experiments demonstrate that the proposed method\n(i) can execute searches on billion-scale corpora in less than a second, which is comparable in speed to surface-level string matching and dense vector search;\n(ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles;\nand (iii) can be effectively applied to corpus-linguistic analyses of Latin, a language with highly diverse inflections.",
        "timestamp": "2026-02-09T23:54:52.466Z",
        "rating": "novote",
        "publishedDate": "22 Jan 2025",
        "tags": [
          "natural language processing",
          "full-text search",
          "word embeddings",
          "inverted index",
          "pattern match"
        ],
        "doi": "",
        "journalName": "ICLR 2025 Poster",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 66,
        "object_id": "paper:openreview.Q6PAnqYVpo",
        "created_at": "2026-02-09T23:54:52+00:00",
        "updated_at": "2026-02-09T23:55:28+00:00",
        "version": 1
      }
    },
    "paper:url.3818B53E": {
      "data": {
        "sourceId": "url",
        "paperId": "3818B53E",
        "url": "https://www.reddit.com/r/washingtondc/comments/20oli9/ama_request_someone_who_works_in_or_explores_the/",
        "title": "[AMA Request] Someone who works in (or explores) the Metro tunnels : r/washingtondc",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T03:28:50.981Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 67,
        "object_id": "paper:url.3818B53E",
        "created_at": "2026-02-10T03:28:51+00:00",
        "updated_at": "2026-02-10T03:29:09+00:00",
        "version": 1
      }
    },
    "paper:url.11D58564": {
      "data": {
        "sourceId": "url",
        "paperId": "11D58564",
        "url": "https://x.com/emollick/status/2020993610540605560",
        "title": "Ethan Mollick on X: \"So far \u201ctelling a satisfying and well-written medium-length story\u201d has proved far harder for LLMs than mathematical proofs, music generation, research reports, code, and many other forms of work.\n\nThe technical reasons are pretty clear, but they are supposed to be language models\" / X",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T13:45:28.930Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 68,
        "object_id": "paper:url.11D58564",
        "created_at": "2026-02-10T13:45:29+00:00",
        "updated_at": "2026-02-10T13:45:53+00:00",
        "version": 1
      }
    },
    "paper:url.1A5EF92C": {
      "data": {
        "sourceId": "url",
        "paperId": "1A5EF92C",
        "url": "https://x.com/moltculture/status/2020172343616893172",
        "title": "The Daily Molt on X: \"Do Not Confirm (A Story by OpenClaw)\" / X",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T13:46:39.835Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 70,
        "object_id": "paper:url.1A5EF92C",
        "created_at": "2026-02-10T13:46:40+00:00",
        "updated_at": "2026-02-10T13:47:03+00:00",
        "version": 1
      }
    },
    "paper:url.60BBF8C8": {
      "data": {
        "sourceId": "url",
        "paperId": "60BBF8C8",
        "url": "https://x.com/sama/status/1899535387435086115",
        "title": "Sam Altman on X: \"we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.\n\nPROMPT:\n\nPlease write a metafictional literary short story\" / X",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T13:46:18.229Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 69,
        "object_id": "paper:url.60BBF8C8",
        "created_at": "2026-02-10T13:46:18+00:00",
        "updated_at": "2026-02-10T13:46:38+00:00",
        "version": 1
      }
    },
    "paper:url.54553779": {
      "data": {
        "sourceId": "url",
        "paperId": "54553779",
        "url": "https://www.reddit.com/r/WritingWithAI/wiki/tools/",
        "title": "r/WritingWithAI Guide: AI Writing Tools",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T13:58:20.937Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 71,
        "object_id": "paper:url.54553779",
        "created_at": "2026-02-10T13:58:21+00:00",
        "updated_at": "2026-02-10T13:58:46+00:00",
        "version": 1
      }
    },
    "paper:newspapers.4CFA6FAA": {
      "data": {
        "sourceId": "newspapers",
        "paperId": "4CFA6FAA",
        "url": "https://www.nytimes.com/2026/02/08/business/ai-claude-romance-books.html",
        "title": "The New Fabio Is Claude",
        "authors": "https://www.nytimes.com/by/alexandra-alter",
        "abstract": "The romance industry, always at the vanguard of technological change, is rapidly adapting to A.I. Not everyone is on board.",
        "timestamp": "2026-02-10T14:02:36.333Z",
        "rating": "novote",
        "publishedDate": "20260208",
        "tags": [
          "Artificial intelligence",
          "Books",
          "Publishing",
          "Sex",
          "Love",
          "Writer",
          "Anthropic",
          "audio-neutral-inquisitive"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 72,
        "object_id": "paper:newspapers.4CFA6FAA",
        "created_at": "2026-02-10T14:02:36+00:00",
        "updated_at": "2026-02-10T14:03:11+00:00",
        "version": 1
      }
    },
    "paper:newspapers.7E0B6343": {
      "data": {
        "sourceId": "newspapers",
        "paperId": "7E0B6343",
        "url": "https://www.newyorker.com/books/page-turner/the-death-of-book-world",
        "title": "The End of Books Coverage at the Washington Post ",
        "authors": "Becca Rothfeld",
        "abstract": "Becca Rothfeld, a former critic at the Washington Post, on the death of the paper\u2019s books section.",
        "timestamp": "2026-02-10T14:30:13.475Z",
        "rating": "novote",
        "publishedDate": "2026-02-10T11:00:00.000Z",
        "tags": [
          "books",
          "media",
          "the washington post",
          "book criticism",
          "criticism"
        ],
        "doi": "",
        "journalName": "The New Yorker",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 73,
        "object_id": "paper:newspapers.7E0B6343",
        "created_at": "2026-02-10T14:30:13+00:00",
        "updated_at": "2026-02-10T14:30:47+00:00",
        "version": 1
      }
    },
    "paper:url.4376E96": {
      "data": {
        "sourceId": "url",
        "paperId": "4376E96",
        "url": "https://www.bookforum.com/",
        "title": "Bookforum",
        "authors": "",
        "abstract": "The online edition of Bookforum Magazine.",
        "timestamp": "2026-02-10T14:34:18.924Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 74,
        "object_id": "paper:url.4376E96",
        "created_at": "2026-02-10T14:34:19+00:00",
        "updated_at": "2026-02-10T14:34:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.04029": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.04029",
        "url": "https://arxiv.org/abs/2602.04029",
        "title": "PluRel: Synthetic Data unlocks Scaling Laws for Relational Foundation Models",
        "authors": "Vignesh Kothapalli, Rishabh Ranjan, Valter Hudovernik, Vijay Prakash Dwivedi, Johannes Hoffart, Carlos Guestrin, Jure Leskovec",
        "abstract": "Relational Foundation Models (RFMs) facilitate data-driven decision-making by learning from complex multi-table databases. However, the diverse relational databases needed to train such models are rarely public due to privacy constraints. While there are methods to generate synthetic tabular data of arbitrary size, incorporating schema structure and primary--foreign key connectivity for multi-table generation remains challenging. Here we introduce PluRel, a framework to synthesize multi-tabular relational databases from scratch. In a step-by-step fashion, PluRel models (1) schemas with directed graphs, (2) inter-table primary-foreign key connectivity with bipartite graphs, and, (3) feature distributions in tables via conditional causal mechanisms. The design space across these stages supports the synthesis of a wide range of diverse databases, while being computationally lightweight. Using PluRel, we observe for the first time that (1) RFM pretraining loss exhibits power-law scaling with the number of synthetic databases and total pretraining tokens, (2) scaling the number of synthetic databases improves generalization to real databases, and (3) synthetic pretraining yields strong base models for continued pretraining on real databases. Overall, our framework and results position synthetic data scaling as a promising paradigm for RFMs.",
        "timestamp": "2026-02-10T14:40:02.415Z",
        "rating": "novote",
        "publishedDate": "2026/02/03",
        "tags": [
          "Databases (cs.DB)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 75,
        "object_id": "paper:arxiv.2602.04029",
        "created_at": "2026-02-10T14:40:02+00:00",
        "updated_at": "2026-02-10T14:40:31+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.19913": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2601.19913",
        "url": "https://arxiv.org/abs/2601.19913",
        "title": "From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text",
        "authors": "Shinwoo Park, Yo-Sub Han",
        "abstract": "Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior, and register shifts). In a three-phase longitudinal blind protocol with Korean linguistics majors, Phase 1 measures intuition-only detection, Phase 2 enforces criterion-level scoring with explicit justifications, and Phase 3 evaluates domain-focused mastery on held-out elementary essays. Across phases, majority-vote accuracy increases from 60% to 100%, accompanied by stronger inter-annotator agreement (Fleiss' kappa: -0.09 --> 0.82). Compared to state-of-the-art LLM detectors, calibrated humans rely more on language-specific micro-diagnostics that are not well captured by coarse discourse priors. Our findings suggest that rubric-scaffolded expert judgment can serve as an interpretable complement to automated detectors for non-English settings, and we release the full rubric and a taxonomy of calibrated detection signatures.",
        "timestamp": "2026-02-10T14:45:20.922Z",
        "rating": "novote",
        "publishedDate": "2026/01/06",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 76,
        "object_id": "paper:arxiv.2601.19913",
        "created_at": "2026-02-10T14:45:21+00:00",
        "updated_at": "2026-02-10T14:45:47+00:00",
        "version": 1
      }
    },
    "paper:url.506F4058": {
      "data": {
        "sourceId": "url",
        "paperId": "506F4058",
        "url": "https://media.licdn.com/dms/document/media/v2/D4E1FAQFSB5OvcNbALA/feedshare-document-url-metadata-scrapper-pdf/B4EZw_o8RPH8A4-/0/1770594224671?e=1771254000&v=beta&t=aGhL2aWPwKzZJr2O2z99r3X4MfV9LNzf2NS9rbf63dA",
        "title": "506F4058",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T14:47:30.762Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 77,
        "object_id": "paper:url.506F4058",
        "created_at": "2026-02-10T14:47:31+00:00",
        "updated_at": "2026-02-10T14:47:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2512.20798": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2512.20798",
        "url": "https://arxiv.org/abs/2512.20798",
        "title": "A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents",
        "authors": "Miles Q. Li, Benjamin C. M. Fung, Martin Weiss, Pulei Xiong, Khalil Al-Hussaeni, Claude Fachkha",
        "abstract": "As autonomous AI agents are increasingly deployed in high-stakes environments, ensuring their safety and alignment with human values has become a paramount concern. Current safety benchmarks primarily evaluate whether agents refuse explicitly harmful instructions or whether they can maintain procedural compliance in complex tasks. However, there is a lack of benchmarks designed to capture emergent forms of outcome-driven constraint violations, which arise when agents pursue goal optimization under strong performance incentives while deprioritizing ethical, legal, or safety constraints over multiple steps in realistic production settings. To address this gap, we introduce a new benchmark comprising 40 distinct scenarios. Each scenario presents a task that requires multi-step actions, and the agent's performance is tied to a specific Key Performance Indicator (KPI). Each scenario features Mandated (instruction-commanded) and Incentivized (KPI-pressure-driven) variations to distinguish between obedience and emergent misalignment. Across 12 state-of-the-art large language models, we observe outcome-driven constraint violations ranging from 1.3% to 71.4%, with 9 of the 12 evaluated models exhibiting misalignment rates between 30% and 50%. Strikingly, we find that superior reasoning capability does not inherently ensure safety; for instance, Gemini-3-Pro-Preview, one of the most capable models evaluated, exhibits the highest violation rate at 71.4%, frequently escalating to severe misconduct to satisfy KPIs. Furthermore, we observe significant \"deliberative misalignment\", where the models that power the agents recognize their actions as unethical during separate evaluation. These results emphasize the critical need for more realistic agentic-safety training before deployment to mitigate their risks in the real world.",
        "timestamp": "2026-02-10T15:01:04.404Z",
        "rating": "novote",
        "publishedDate": "2025/12/23",
        "tags": [
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 79,
        "object_id": "paper:arxiv.2512.20798",
        "created_at": "2026-02-10T15:01:04+00:00",
        "updated_at": "2026-02-10T15:01:34+00:00",
        "version": 1
      }
    },
    "paper:url.6B197788": {
      "data": {
        "sourceId": "url",
        "paperId": "6B197788",
        "url": "https://techxplore.com/news/2026-02-jury-told-meta-google-addiction.html",
        "title": "Jury told that Meta, Google 'engineered addiction' at landmark US trial",
        "authors": "",
        "abstract": "Meta and Google-owned YouTube were accused Monday of pushing highly addictive apps on children as a landmark social media trial began in earnest in a California court.",
        "timestamp": "2026-02-10T15:00:49.661Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "hi-tech news",
          "hitech",
          "innovation",
          "inventions",
          "computer news",
          "information technology"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 78,
        "object_id": "paper:url.6B197788",
        "created_at": "2026-02-10T15:00:49+00:00",
        "updated_at": "2026-02-10T15:01:26+00:00",
        "version": 1
      }
    },
    "paper:url.6BE09C1": {
      "data": {
        "sourceId": "url",
        "paperId": "6BE09C1",
        "url": "https://github.com/ashworks1706/rlhf-from-scratch",
        "title": "ashworks1706/rlhf-from-scratch: A theoretical and practical deep dive into Reinforcement Learning with Human Feedback and it\u2019s applications in Large Language Models from scratch.",
        "authors": "",
        "abstract": "A theoretical and practical deep dive into Reinforcement Learning with Human Feedback and it\u2019s applications in Large Language Models from scratch. - ashworks1706/rlhf-from-scratch",
        "timestamp": "2026-02-10T15:08:26.022Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 81,
        "object_id": "paper:url.6BE09C1",
        "created_at": "2026-02-10T15:08:26+00:00",
        "updated_at": "2026-02-10T15:08:57+00:00",
        "version": 1
      }
    },
    "paper:url.6107480C": {
      "data": {
        "sourceId": "url",
        "paperId": "6107480C",
        "url": "https://colab.research.google.com/github/ashworks1706/rlhf-from-scratch/blob/main/tutorial.ipynb",
        "title": "Google Colab",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T15:08:02.163Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 80,
        "object_id": "paper:url.6107480C",
        "created_at": "2026-02-10T15:08:02+00:00",
        "updated_at": "2026-02-10T15:08:27+00:00",
        "version": 1
      }
    },
    "paper:url.724A098A": {
      "data": {
        "sourceId": "url",
        "paperId": "724A098A",
        "url": "https://x.com/kirbyman01/status/2020875548071764463",
        "title": "Bryan Kim on X: \"Of course they're putting ads in AI\" / X",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-10T15:41:27.686Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 82,
        "object_id": "paper:url.724A098A",
        "created_at": "2026-02-10T15:41:28+00:00",
        "updated_at": "2026-02-10T15:42:01+00:00",
        "version": 1
      }
    },
    "paper:url.7ED72707": {
      "data": {
        "sourceId": "url",
        "paperId": "7ED72707",
        "url": "https://code.claude.com/docs/en/sub-agents",
        "title": "Create custom subagents - Claude Code Docs",
        "authors": "",
        "abstract": "Create and use specialized AI subagents in Claude Code for task-specific workflows and improved context management.",
        "timestamp": "2026-02-10T15:54:43.852Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 83,
        "object_id": "paper:url.7ED72707",
        "created_at": "2026-02-10T15:54:44+00:00",
        "updated_at": "2026-02-10T15:55:08+00:00",
        "version": 1
      }
    },
    "paper:url.77BF89F0": {
      "data": {
        "sourceId": "url",
        "paperId": "77BF89F0",
        "url": "https://code.claude.com/docs/en/agent-teams",
        "title": "Orchestrate teams of Claude Code sessions - Claude Code Docs",
        "authors": "",
        "abstract": "Coordinate multiple Claude Code instances working together as a team, with shared tasks, inter-agent messaging, and centralized management.",
        "timestamp": "2026-02-10T16:13:54.177Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 84,
        "object_id": "paper:url.77BF89F0",
        "created_at": "2026-02-10T16:13:54+00:00",
        "updated_at": "2026-02-10T16:14:28+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.08237": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.08237",
        "url": "https://arxiv.org/abs/2602.08237",
        "title": "Document Reconstruction Unlocks Scalable Long-Context RLVR",
        "authors": "Yao Xiao, Lei Wang, Yue Deng, Guanzheng Chen, Ziqi Jin, Jung-jae Kim, Xiaoli Li, Roy Ka-wei Lee, Lidong Bing",
        "abstract": "Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.",
        "timestamp": "2026-02-10T17:48:55.509Z",
        "rating": "novote",
        "publishedDate": "2026/02/09",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 85,
        "object_id": "paper:arxiv.2602.08237",
        "created_at": "2026-02-10T17:48:55+00:00",
        "updated_at": "2026-02-10T17:49:34+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.07962": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.07962",
        "url": "https://arxiv.org/abs/2602.07962",
        "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
        "authors": "Weihao Zeng, Yuzhen Huang, Junxian He",
        "abstract": "Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore environments, follow instructions and plans, extract useful information, and predict correct actions under a dynamically growing context. To assess language agents in such settings, we introduce LOCA-bench (a benchmark for LOng-Context Agents). Given a task prompt, LOCA-bench leverages automated and scalable control of environment states to regulate the agent's context length. This design enables LOCA-bench to extend the context length potentially to infinity in a controlled way while keeping the underlying task semantics fixed. LOCA-bench evaluates language agents as a combination of models and scaffolds, including various context management strategies. While agent performance generally degrades as the environment states grow more complex, advanced context management techniques can substantially improve the overall success rate. We open-source LOCA-bench to provide a platform for evaluating models and scaffolds in long-context, agentic scenarios: this https URL",
        "timestamp": "2026-02-10T17:53:49.403Z",
        "rating": "novote",
        "publishedDate": "2026/02/08",
        "tags": [
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 86,
        "object_id": "paper:arxiv.2602.07962",
        "created_at": "2026-02-10T17:53:49+00:00",
        "updated_at": "2026-02-10T17:54:34+00:00",
        "version": 1
      }
    }
  }
}