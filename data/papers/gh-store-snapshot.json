{
  "snapshot_time": "2026-02-09T13:49:03.951349+00:00",
  "repository": "chtmp223/papers-feed",
  "objects": {
    "paper:nber.w34777": {
      "data": {
        "rating": "novote",
        "doi": "10.3386/w34777",
        "timestamp": "2026-02-08T01:07:44.172Z",
        "abstract": "Founded in 1920, the NBER is a private, non-profit, non-partisan organization dedicated to conducting economic research and to disseminating research findings among academics, public policy makers, and business professionals.",
        "url": "https://www.nber.org/papers/w34777",
        "authors": "Imke Reimers, Joel Waldfogel",
        "publishedDate": "2026/02/02",
        "title": "AI and the Quantity and Quality of Creative Products: Have LLMs Boosted Creation of Valuable Books?",
        "sourceId": "nber",
        "tags": [
          "Imke Reimers",
          "Joel Waldfogel"
        ],
        "paperId": "w34777",
        "journalName": "NBER Working Papers",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 12,
        "object_id": "paper:nber.w34777",
        "created_at": "2026-02-08T01:07:44+00:00",
        "updated_at": "2026-02-08T01:08:12+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.05125": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T01:23:36.193Z",
        "abstract": "Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.",
        "url": "https://arxiv.org/abs/2602.05125",
        "authors": "William F. Shen, Xinchi Qiu, Chenxi Whitehouse, Lisa Alazraki, Shashwat Goel, Francesco Barbieri, Timon Willi, Akhil Mathur, Ilias Leontiadis",
        "publishedDate": "2026/02/04",
        "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "paperId": "2602.05125",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 13,
        "object_id": "paper:arxiv.2602.05125",
        "created_at": "2026-02-08T01:23:36+00:00",
        "updated_at": "2026-02-08T01:23:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.21996": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:10:02.187Z",
        "abstract": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.",
        "url": "https://arxiv.org/abs/2601.21996",
        "authors": "Jianhui Chen, Yuzhang Luo, Liangming Pan",
        "publishedDate": "2026/01/29",
        "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
        "sourceId": "arxiv",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2601.21996",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 15,
        "object_id": "paper:arxiv.2601.21996",
        "created_at": "2026-02-08T02:10:02+00:00",
        "updated_at": "2026-02-08T02:10:26+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.12501": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:09:57.564Z",
        "abstract": "Reinforcement learning from human feedback (RLHF) has become an important technical and storytelling tool to deploy the latest machine learning systems. In this book, we hope to give a gentle introduction to the core methods for people with some level of quantitative background. The book starts with the origins of RLHF -- both in recent literature and in a convergence of disparate fields of science in economics, philosophy, and optimal control. We then set the stage with definitions, problem formulation, data collection, and other common math used in the literature. The core of the book details every optimization stage in using RLHF, from starting with instruction tuning to training a reward model and finally all of rejection sampling, reinforcement learning, and direct alignment algorithms. The book concludes with advanced topics -- understudied research questions in synthetic data and evaluation -- and open questions for the field.",
        "url": "https://arxiv.org/abs/2504.12501",
        "authors": "Nathan Lambert",
        "publishedDate": "2025/04/16",
        "title": "Reinforcement Learning from Human Feedback",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2504.12501",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 14,
        "object_id": "paper:arxiv.2504.12501",
        "created_at": "2026-02-08T02:09:57+00:00",
        "updated_at": "2026-02-08T02:10:16+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.03183": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.03183",
        "url": "https://arxiv.org/abs/2602.03183",
        "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
        "authors": "Hyunwoo Kim, Niloofar Mireshghallah, Michael Duan, Rui Xin, Shuyue Stella Li, Jaehun Jung, David Acuna, Qi Pang, Hanshen Xiao, G. Edward Suh, Sewoong Oh, Yulia Tsvetkov, Pang Wei Koh, Yejin Choi",
        "abstract": "Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.",
        "timestamp": "2026-02-08T15:57:27.140Z",
        "rating": "novote",
        "publishedDate": "2026/02/03",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 16,
        "object_id": "paper:arxiv.2602.03183",
        "created_at": "2026-02-08T15:57:27+00:00",
        "updated_at": "2026-02-08T15:59:45+00:00",
        "version": 1
      }
    },
    "paper:url.7BCFC2D3": {
      "data": {
        "sourceId": "url",
        "paperId": "7BCFC2D3",
        "url": "https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/",
        "title": "I Am Happier Writing Code by Hand",
        "authors": "Abhinav Omprakash",
        "abstract": "I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work and my phone. \u201cWhat\u2019s the point of it all?\u201d I thought, LLMs can generate decent-ish and correct-ish looking code while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow?",
        "timestamp": "2026-02-08T16:11:42.767Z",
        "rating": "novote",
        "publishedDate": "2026-02-07T15:30:23+02:00",
        "tags": [
          "essays"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 17,
        "object_id": "paper:url.7BCFC2D3",
        "created_at": "2026-02-08T16:11:42+00:00",
        "updated_at": "2026-02-08T16:12:02+00:00",
        "version": 1
      }
    },
    "paper:url.64A41AB2": {
      "data": {
        "sourceId": "url",
        "paperId": "64A41AB2",
        "url": "https://siddhantkhare.com/writing/ai-fatigue-is-real",
        "title": "AI fatigue is real and nobody talks about it | Siddhant Khare",
        "authors": "Siddhant Khare",
        "abstract": "You're using AI to be more productive. So why are you more exhausted than ever? The paradox every engineer needs to confront.",
        "timestamp": "2026-02-08T16:30:33.826Z",
        "rating": "novote",
        "publishedDate": "2026-02-08",
        "tags": [
          "Siddhant Khare",
          "AI agent infrastructure",
          "LLM agents",
          "agentic AI",
          "AI security",
          "OpenFGA",
          "CNCF",
          "memory systems",
          "authorization",
          "ReBAC",
          "agent orchestration",
          "context engineering",
          "context efficiency",
          "RAG deduplication",
          "KV-cache",
          "inference optimization",
          "software engineer",
          "open source",
          "Gitpod",
          "Ona",
          "machine learning infrastructure",
          "Zanzibar authorization",
          "distributed systems",
          "GPU profiling",
          "MCP servers"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 19,
        "object_id": "paper:url.64A41AB2",
        "created_at": "2026-02-08T16:30:34+00:00",
        "updated_at": "2026-02-08T16:30:53+00:00",
        "version": 1
      }
    },
    "paper:url.4F5694F4": {
      "data": {
        "sourceId": "url",
        "paperId": "4F5694F4",
        "url": "https://daplab.cs.columbia.edu/general/2026/01/07/why-vibe-coding-fails-and-how-to-fix-it.html",
        "title": "DAPLab - Data, Agents, and Processes | Columbia University",
        "authors": "DAPLab, Columbia University",
        "abstract": "A research lab at Columbia University working at the intersection of AI, systems, and automation.",
        "timestamp": "2026-02-08T16:30:05.829Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "DAPLab",
          "Columbia University",
          "agent-based systems",
          "systems research",
          "AI safety",
          "RL",
          "ML",
          "HCI",
          "cloud computing",
          "large language models",
          "trustworthy AI",
          "automation research",
          "operations research"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 18,
        "object_id": "paper:url.4F5694F4",
        "created_at": "2026-02-08T16:30:06+00:00",
        "updated_at": "2026-02-08T16:30:24+00:00",
        "version": 1
      }
    },
    "paper:url.7744C59C": {
      "data": {
        "sourceId": "url",
        "paperId": "7744C59C",
        "url": "https://aeon.co/videos/the-elaborate-places-ones-mind-wanders-in-solitary-confinement?utm_source=rss-feed",
        "title": "The elaborate places one\u2019s mind wanders in solitary confinement | Aeon Videos",
        "authors": "",
        "abstract": "Where does the mind go in solitary confinement? An evocative animation exploring three individual experiences",
        "timestamp": "2026-02-08T17:02:29.616Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 20,
        "object_id": "paper:url.7744C59C",
        "created_at": "2026-02-08T17:02:29+00:00",
        "updated_at": "2026-02-08T17:02:47+00:00",
        "version": 1
      }
    },
    "paper:url.214C1B64": {
      "data": {
        "sourceId": "url",
        "paperId": "214C1B64",
        "url": "https://ezhik.jp/ai-slop-terrifies-me/",
        "title": "(AI) Slop Terrifies Me \u2013 ezhik.jp",
        "authors": "",
        "abstract": "What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?",
        "timestamp": "2026-02-08T17:04:48.390Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 22,
        "object_id": "paper:url.214C1B64",
        "created_at": "2026-02-08T17:04:48+00:00",
        "updated_at": "2026-02-08T17:05:05+00:00",
        "version": 1
      }
    },
    "paper:url-misc.223BF1B6": {
      "data": {
        "sourceId": "url-misc",
        "paperId": "223BF1B6",
        "url": "https://pubmed.ncbi.nlm.nih.gov/41506004/",
        "title": "Blood omega-3 is inversely related to risk of early-onset dementia",
        "authors": "",
        "abstract": "This study expands the evidence of a beneficial association of omega-3 and LOD to EOD as well. These findings suggest that an increased intake of omega-3 fatty acids earlier in life may slow the development of EOD. Additional research is needed to confirm our findings, particularly in more diverse p \u2026",
        "timestamp": "2026-02-08T17:04:30.033Z",
        "rating": "novote",
        "publishedDate": "2026 Feb",
        "tags": [
          "pmid:41506004",
          "doi:10.1016/j.clnu.2025.106559",
          "Aleix Sala-Vila",
          "Nathan L Tintle",
          "William S Harris",
          "Adult",
          "Age of Onset",
          "Apolipoprotein E4 / genetics",
          "Cohort Studies",
          "Dementia* / blood",
          "Dementia* / epidemiology",
          "Dementia* / genetics",
          "Dementia* / prevention & control",
          "Diet* / statistics & numerical data",
          "Fatty Acids",
          "Omega-3* / blood",
          "Female",
          "Humans",
          "Male",
          "Middle Aged",
          "Proportional Hazards Models",
          "Risk Factors",
          "United Kingdom / epidemiology",
          "PubMed Abstract",
          "NIH",
          "NLM",
          "NCBI",
          "National Institutes of Health",
          "National Center for Biotechnology Information",
          "National Library of Medicine",
          "MEDLINE"
        ],
        "doi": "10.1016/j.clnu.2025.106559",
        "journalName": "Clinical nutrition (Edinburgh, Scotland)",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 21,
        "object_id": "paper:url-misc.223BF1B6",
        "created_at": "2026-02-08T17:04:30+00:00",
        "updated_at": "2026-02-08T17:04:50+00:00",
        "version": 1
      }
    },
    "paper:url.756E9B46": {
      "data": {
        "sourceId": "url",
        "paperId": "756E9B46",
        "url": "https://platform.claude.com/docs/en/agent-sdk/overview",
        "title": "Agent SDK overview",
        "authors": "",
        "abstract": "Build production AI agents with Claude Code as a library",
        "timestamp": "2026-02-08T21:33:07.955Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 23,
        "object_id": "paper:url.756E9B46",
        "created_at": "2026-02-08T21:33:08+00:00",
        "updated_at": "2026-02-08T21:33:27+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2408.08506": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2408.08506",
        "url": "https://arxiv.org/abs/2408.08506",
        "title": "Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding",
        "authors": "Lei Huang, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen",
        "abstract": "Generating long-term texts such as novels using artificial intelligence has always been a challenge. A common approach is to use large language models (LLMs) to construct a hierarchical framework that first plans and then writes. Despite the fact that the generated novels reach a sufficient length, they exhibit poor logical coherence and appeal in their plots and deficiencies in character and event depiction, ultimately compromising the overall narrative quality. In this paper, we propose a method named Extracting Excelsior and Expanding. Ex3 initially extracts structure information from raw novel data. By combining this structure information with the novel data, an instruction-following dataset is meticulously crafted. This dataset is then utilized to fine-tune the LLM, aiming for excelsior generation performance. In the final stage, a tree-like expansion method is deployed to facilitate the generation of arbitrarily long novels. Evaluation against previous methods showcases Ex3's ability to produce higher-quality long-form novels.",
        "timestamp": "2026-02-08T21:35:30.344Z",
        "rating": "novote",
        "publishedDate": "2024/08/16",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 24,
        "object_id": "paper:arxiv.2408.08506",
        "created_at": "2026-02-08T21:35:30+00:00",
        "updated_at": "2026-02-08T21:35:48+00:00",
        "version": 1
      }
    },
    "paper:openreview.H1ncX6O6Yh": {
      "data": {
        "sourceId": "openreview",
        "paperId": "H1ncX6O6Yh",
        "url": "https://openreview.net/forum?id=H1ncX6O6Yh",
        "title": "Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games",
        "authors": "",
        "abstract": "Large Language Model (LLM) agents are reshaping the game industry, by enabling more intelligent and human-preferable characters. Yet, current game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets to adapt pre-trained LLMs into gaming agents. To fill these gaps, we present Orak, a benchmark for training and evaluating LLM agents across 12 popular video games spanning all major genres. Using a plug-and-play interface built on Model Context Protocol (MCP), Orak supports systematic and reproducible studies of agentic modules in varied game scenarios. We further release a fine-tuning dataset of expert LLM gameplay trajectories spanning multiple genres, turning general LLMs into effective game agents. Orak offers a comprehensive evaluation framework, including game leaderboards, LLM battle arenas, and in-depth analyses of input modality, agentic strategies, and fine-tuning effects, establishing a foundation towards versatile gaming agents. Code is available at https://anonymous.4open.science/r/Orak-5013/.",
        "timestamp": "2026-02-08T22:18:39.325Z",
        "rating": "novote",
        "publishedDate": "26 Jan 2026",
        "tags": [
          "LLM",
          "Agents",
          "Benchmark",
          "Games"
        ],
        "doi": "",
        "journalName": "ICLR 2026 Poster",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 26,
        "object_id": "paper:openreview.H1ncX6O6Yh",
        "created_at": "2026-02-08T22:18:39+00:00",
        "updated_at": "2026-02-08T22:18:55+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2503.15655": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2503.15655",
        "url": "https://arxiv.org/abs/2503.15655",
        "title": "R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs",
        "authors": "Zefeng Lin, Yi Xiao, Zhiqiang Mo, Qifan Zhang, Jie Wang, Jiayang Chen, Jiajing Zhang, Hui Zhang, Zhengyi Liu, Xianyong Fang, Xiaohua Xu",
        "abstract": "Automatically adapting novels into screenplays is important for the TV, film, or opera industries to promote products with low costs. The strong performances of large language models (LLMs) in long-text generation call us to propose a LLM based framework Reader-Rewriter (R2^2) for this task. However, there are two fundamental challenges here. First, the LLM hallucinations may cause inconsistent plot extraction and screenplay generation. Second, the causality-embedded plot lines should be effectively extracted for coherent rewriting. Therefore, two corresponding tactics are proposed: 1) A hallucination-aware refinement method (HAR) to iteratively discover and eliminate the affections of hallucinations; and 2) a causal plot-graph construction method (CPC) based on a greedy cycle-breaking algorithm to efficiently construct plot lines with event causalities. Recruiting those efficient techniques, R2^2 utilizes two modules to mimic the human screenplay rewriting process: The Reader module adopts a sliding window and CPC to build the causal plot graphs, while the Rewriter module generates first the scene outlines based on the graphs and then the screenplays. HAR is integrated into both modules for accurate inferences of LLMs. Experimental results demonstrate the superiority of R2^2, which substantially outperforms three existing approaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison at the overall win rate for GPT-4o.",
        "timestamp": "2026-02-08T22:18:27.981Z",
        "rating": "novote",
        "publishedDate": "2025/03/19",
        "tags": [
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 25,
        "object_id": "paper:arxiv.2503.15655",
        "created_at": "2026-02-08T22:18:28+00:00",
        "updated_at": "2026-02-08T22:18:47+00:00",
        "version": 1
      }
    },
    "paper:url.46149ECF": {
      "data": {
        "sourceId": "url",
        "paperId": "46149ECF",
        "url": "https://www.theatlantic.com/ideas/2026/02/books-news-washington-post/685897/?utm_source=feed",
        "title": "The Literary Ecosystem Is Dying",
        "authors": "Adam Kirsch",
        "abstract": "In a sense, the decline of book reviews, like the decline of newspapers themselves, is a story about disaggregation.",
        "timestamp": "2026-02-09T00:23:17.078Z",
        "rating": "novote",
        "publishedDate": "2026-02-06T12:00:00Z",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 27,
        "object_id": "paper:url.46149ECF",
        "created_at": "2026-02-09T00:23:17+00:00",
        "updated_at": "2026-02-09T00:23:35+00:00",
        "version": 1
      }
    },
    "paper:url.2DB787B1": {
      "data": {
        "sourceId": "url",
        "paperId": "2DB787B1",
        "url": "https://odd-lots-books.netlify.app/",
        "title": "Odd Lots Books",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T02:09:07.679Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 28,
        "object_id": "paper:url.2DB787B1",
        "created_at": "2026-02-09T02:09:07+00:00",
        "updated_at": "2026-02-09T02:09:29+00:00",
        "version": 1
      }
    },
    "paper:url.35111C3C": {
      "data": {
        "sourceId": "url",
        "paperId": "35111C3C",
        "url": "https://github.com/yanaiela/service",
        "title": "yanaiela/service: library for different service automation",
        "authors": "",
        "abstract": "library for different service automation. Contribute to yanaiela/service development by creating an account on GitHub.",
        "timestamp": "2026-02-09T13:48:20.134Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 29,
        "object_id": "paper:url.35111C3C",
        "created_at": "2026-02-09T13:48:20+00:00",
        "updated_at": "2026-02-09T13:48:40+00:00",
        "version": 1
      }
    }
  }
}