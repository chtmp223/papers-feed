{
  "snapshot_time": "2026-02-09T21:34:51.126920+00:00",
  "repository": "chtmp223/papers-feed",
  "objects": {
    "paper:nber.w34777": {
      "data": {
        "rating": "novote",
        "doi": "10.3386/w34777",
        "timestamp": "2026-02-08T01:07:44.172Z",
        "abstract": "Founded in 1920, the NBER is a private, non-profit, non-partisan organization dedicated to conducting economic research and to disseminating research findings among academics, public policy makers, and business professionals.",
        "url": "https://www.nber.org/papers/w34777",
        "authors": "Imke Reimers, Joel Waldfogel",
        "publishedDate": "2026/02/02",
        "title": "AI and the Quantity and Quality of Creative Products: Have LLMs Boosted Creation of Valuable Books?",
        "sourceId": "nber",
        "tags": [
          "Imke Reimers",
          "Joel Waldfogel"
        ],
        "paperId": "w34777",
        "journalName": "NBER Working Papers",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 12,
        "object_id": "paper:nber.w34777",
        "created_at": "2026-02-08T01:07:44+00:00",
        "updated_at": "2026-02-08T01:08:12+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.05125": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T01:23:36.193Z",
        "abstract": "Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.",
        "url": "https://arxiv.org/abs/2602.05125",
        "authors": "William F. Shen, Xinchi Qiu, Chenxi Whitehouse, Lisa Alazraki, Shashwat Goel, Francesco Barbieri, Timon Willi, Akhil Mathur, Ilias Leontiadis",
        "publishedDate": "2026/02/04",
        "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "paperId": "2602.05125",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 13,
        "object_id": "paper:arxiv.2602.05125",
        "created_at": "2026-02-08T01:23:36+00:00",
        "updated_at": "2026-02-08T01:23:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.21996": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:10:02.187Z",
        "abstract": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.",
        "url": "https://arxiv.org/abs/2601.21996",
        "authors": "Jianhui Chen, Yuzhang Luo, Liangming Pan",
        "publishedDate": "2026/01/29",
        "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
        "sourceId": "arxiv",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2601.21996",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 15,
        "object_id": "paper:arxiv.2601.21996",
        "created_at": "2026-02-08T02:10:02+00:00",
        "updated_at": "2026-02-08T02:10:26+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.12501": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:09:57.564Z",
        "abstract": "Reinforcement learning from human feedback (RLHF) has become an important technical and storytelling tool to deploy the latest machine learning systems. In this book, we hope to give a gentle introduction to the core methods for people with some level of quantitative background. The book starts with the origins of RLHF -- both in recent literature and in a convergence of disparate fields of science in economics, philosophy, and optimal control. We then set the stage with definitions, problem formulation, data collection, and other common math used in the literature. The core of the book details every optimization stage in using RLHF, from starting with instruction tuning to training a reward model and finally all of rejection sampling, reinforcement learning, and direct alignment algorithms. The book concludes with advanced topics -- understudied research questions in synthetic data and evaluation -- and open questions for the field.",
        "url": "https://arxiv.org/abs/2504.12501",
        "authors": "Nathan Lambert",
        "publishedDate": "2025/04/16",
        "title": "Reinforcement Learning from Human Feedback",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2504.12501",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 14,
        "object_id": "paper:arxiv.2504.12501",
        "created_at": "2026-02-08T02:09:57+00:00",
        "updated_at": "2026-02-08T02:10:16+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.03183": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.03183",
        "url": "https://arxiv.org/abs/2602.03183",
        "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
        "authors": "Hyunwoo Kim, Niloofar Mireshghallah, Michael Duan, Rui Xin, Shuyue Stella Li, Jaehun Jung, David Acuna, Qi Pang, Hanshen Xiao, G. Edward Suh, Sewoong Oh, Yulia Tsvetkov, Pang Wei Koh, Yejin Choi",
        "abstract": "Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.",
        "timestamp": "2026-02-08T15:57:27.140Z",
        "rating": "novote",
        "publishedDate": "2026/02/03",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 16,
        "object_id": "paper:arxiv.2602.03183",
        "created_at": "2026-02-08T15:57:27+00:00",
        "updated_at": "2026-02-08T15:59:45+00:00",
        "version": 1
      }
    },
    "paper:url.7BCFC2D3": {
      "data": {
        "sourceId": "url",
        "paperId": "7BCFC2D3",
        "url": "https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/",
        "title": "I Am Happier Writing Code by Hand",
        "authors": "Abhinav Omprakash",
        "abstract": "I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work and my phone. \u201cWhat\u2019s the point of it all?\u201d I thought, LLMs can generate decent-ish and correct-ish looking code while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow?",
        "timestamp": "2026-02-08T16:11:42.767Z",
        "rating": "novote",
        "publishedDate": "2026-02-07T15:30:23+02:00",
        "tags": [
          "essays"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 17,
        "object_id": "paper:url.7BCFC2D3",
        "created_at": "2026-02-08T16:11:42+00:00",
        "updated_at": "2026-02-08T16:12:02+00:00",
        "version": 1
      }
    },
    "paper:url.64A41AB2": {
      "data": {
        "sourceId": "url",
        "paperId": "64A41AB2",
        "url": "https://siddhantkhare.com/writing/ai-fatigue-is-real",
        "title": "AI fatigue is real and nobody talks about it | Siddhant Khare",
        "authors": "Siddhant Khare",
        "abstract": "You're using AI to be more productive. So why are you more exhausted than ever? The paradox every engineer needs to confront.",
        "timestamp": "2026-02-08T16:30:33.826Z",
        "rating": "novote",
        "publishedDate": "2026-02-08",
        "tags": [
          "Siddhant Khare",
          "AI agent infrastructure",
          "LLM agents",
          "agentic AI",
          "AI security",
          "OpenFGA",
          "CNCF",
          "memory systems",
          "authorization",
          "ReBAC",
          "agent orchestration",
          "context engineering",
          "context efficiency",
          "RAG deduplication",
          "KV-cache",
          "inference optimization",
          "software engineer",
          "open source",
          "Gitpod",
          "Ona",
          "machine learning infrastructure",
          "Zanzibar authorization",
          "distributed systems",
          "GPU profiling",
          "MCP servers"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 19,
        "object_id": "paper:url.64A41AB2",
        "created_at": "2026-02-08T16:30:34+00:00",
        "updated_at": "2026-02-08T16:30:53+00:00",
        "version": 1
      }
    },
    "paper:url.4F5694F4": {
      "data": {
        "sourceId": "url",
        "paperId": "4F5694F4",
        "url": "https://daplab.cs.columbia.edu/general/2026/01/07/why-vibe-coding-fails-and-how-to-fix-it.html",
        "title": "DAPLab - Data, Agents, and Processes | Columbia University",
        "authors": "DAPLab, Columbia University",
        "abstract": "A research lab at Columbia University working at the intersection of AI, systems, and automation.",
        "timestamp": "2026-02-08T16:30:05.829Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "DAPLab",
          "Columbia University",
          "agent-based systems",
          "systems research",
          "AI safety",
          "RL",
          "ML",
          "HCI",
          "cloud computing",
          "large language models",
          "trustworthy AI",
          "automation research",
          "operations research"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 18,
        "object_id": "paper:url.4F5694F4",
        "created_at": "2026-02-08T16:30:06+00:00",
        "updated_at": "2026-02-08T16:30:24+00:00",
        "version": 1
      }
    },
    "paper:url.7744C59C": {
      "data": {
        "sourceId": "url",
        "paperId": "7744C59C",
        "url": "https://aeon.co/videos/the-elaborate-places-ones-mind-wanders-in-solitary-confinement?utm_source=rss-feed",
        "title": "The elaborate places one\u2019s mind wanders in solitary confinement | Aeon Videos",
        "authors": "",
        "abstract": "Where does the mind go in solitary confinement? An evocative animation exploring three individual experiences",
        "timestamp": "2026-02-08T17:02:29.616Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 20,
        "object_id": "paper:url.7744C59C",
        "created_at": "2026-02-08T17:02:29+00:00",
        "updated_at": "2026-02-08T17:02:47+00:00",
        "version": 1
      }
    },
    "paper:url.214C1B64": {
      "data": {
        "sourceId": "url",
        "paperId": "214C1B64",
        "url": "https://ezhik.jp/ai-slop-terrifies-me/",
        "title": "(AI) Slop Terrifies Me \u2013 ezhik.jp",
        "authors": "",
        "abstract": "What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?",
        "timestamp": "2026-02-08T17:04:48.390Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 22,
        "object_id": "paper:url.214C1B64",
        "created_at": "2026-02-08T17:04:48+00:00",
        "updated_at": "2026-02-08T17:05:05+00:00",
        "version": 1
      }
    },
    "paper:url-misc.223BF1B6": {
      "data": {
        "sourceId": "url-misc",
        "paperId": "223BF1B6",
        "url": "https://pubmed.ncbi.nlm.nih.gov/41506004/",
        "title": "Blood omega-3 is inversely related to risk of early-onset dementia",
        "authors": "",
        "abstract": "This study expands the evidence of a beneficial association of omega-3 and LOD to EOD as well. These findings suggest that an increased intake of omega-3 fatty acids earlier in life may slow the development of EOD. Additional research is needed to confirm our findings, particularly in more diverse p \u2026",
        "timestamp": "2026-02-08T17:04:30.033Z",
        "rating": "novote",
        "publishedDate": "2026 Feb",
        "tags": [
          "pmid:41506004",
          "doi:10.1016/j.clnu.2025.106559",
          "Aleix Sala-Vila",
          "Nathan L Tintle",
          "William S Harris",
          "Adult",
          "Age of Onset",
          "Apolipoprotein E4 / genetics",
          "Cohort Studies",
          "Dementia* / blood",
          "Dementia* / epidemiology",
          "Dementia* / genetics",
          "Dementia* / prevention & control",
          "Diet* / statistics & numerical data",
          "Fatty Acids",
          "Omega-3* / blood",
          "Female",
          "Humans",
          "Male",
          "Middle Aged",
          "Proportional Hazards Models",
          "Risk Factors",
          "United Kingdom / epidemiology",
          "PubMed Abstract",
          "NIH",
          "NLM",
          "NCBI",
          "National Institutes of Health",
          "National Center for Biotechnology Information",
          "National Library of Medicine",
          "MEDLINE"
        ],
        "doi": "10.1016/j.clnu.2025.106559",
        "journalName": "Clinical nutrition (Edinburgh, Scotland)",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 21,
        "object_id": "paper:url-misc.223BF1B6",
        "created_at": "2026-02-08T17:04:30+00:00",
        "updated_at": "2026-02-08T17:04:50+00:00",
        "version": 1
      }
    },
    "paper:url.756E9B46": {
      "data": {
        "sourceId": "url",
        "paperId": "756E9B46",
        "url": "https://platform.claude.com/docs/en/agent-sdk/overview",
        "title": "Agent SDK overview",
        "authors": "",
        "abstract": "Build production AI agents with Claude Code as a library",
        "timestamp": "2026-02-08T21:33:07.955Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 23,
        "object_id": "paper:url.756E9B46",
        "created_at": "2026-02-08T21:33:08+00:00",
        "updated_at": "2026-02-08T21:33:27+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2408.08506": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2408.08506",
        "url": "https://arxiv.org/abs/2408.08506",
        "title": "Ex3: Automatic Novel Writing by Extracting, Excelsior and Expanding",
        "authors": "Lei Huang, Jiaming Guo, Guanhua He, Xishan Zhang, Rui Zhang, Shaohui Peng, Shaoli Liu, Tianshi Chen",
        "abstract": "Generating long-term texts such as novels using artificial intelligence has always been a challenge. A common approach is to use large language models (LLMs) to construct a hierarchical framework that first plans and then writes. Despite the fact that the generated novels reach a sufficient length, they exhibit poor logical coherence and appeal in their plots and deficiencies in character and event depiction, ultimately compromising the overall narrative quality. In this paper, we propose a method named Extracting Excelsior and Expanding. Ex3 initially extracts structure information from raw novel data. By combining this structure information with the novel data, an instruction-following dataset is meticulously crafted. This dataset is then utilized to fine-tune the LLM, aiming for excelsior generation performance. In the final stage, a tree-like expansion method is deployed to facilitate the generation of arbitrarily long novels. Evaluation against previous methods showcases Ex3's ability to produce higher-quality long-form novels.",
        "timestamp": "2026-02-08T21:35:30.344Z",
        "rating": "novote",
        "publishedDate": "2024/08/16",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 24,
        "object_id": "paper:arxiv.2408.08506",
        "created_at": "2026-02-08T21:35:30+00:00",
        "updated_at": "2026-02-08T21:35:48+00:00",
        "version": 1
      }
    },
    "paper:openreview.H1ncX6O6Yh": {
      "data": {
        "sourceId": "openreview",
        "paperId": "H1ncX6O6Yh",
        "url": "https://openreview.net/forum?id=H1ncX6O6Yh",
        "title": "Orak: A Foundational Benchmark for Training and Evaluating LLM Agents on Diverse Video Games",
        "authors": "",
        "abstract": "Large Language Model (LLM) agents are reshaping the game industry, by enabling more intelligent and human-preferable characters. Yet, current game benchmarks fall short of practical needs: they lack evaluations of diverse LLM capabilities across various game genres, studies of agentic modules crucial for complex gameplay, and fine-tuning datasets to adapt pre-trained LLMs into gaming agents. To fill these gaps, we present Orak, a benchmark for training and evaluating LLM agents across 12 popular video games spanning all major genres. Using a plug-and-play interface built on Model Context Protocol (MCP), Orak supports systematic and reproducible studies of agentic modules in varied game scenarios. We further release a fine-tuning dataset of expert LLM gameplay trajectories spanning multiple genres, turning general LLMs into effective game agents. Orak offers a comprehensive evaluation framework, including game leaderboards, LLM battle arenas, and in-depth analyses of input modality, agentic strategies, and fine-tuning effects, establishing a foundation towards versatile gaming agents. Code is available at https://anonymous.4open.science/r/Orak-5013/.",
        "timestamp": "2026-02-08T22:18:39.325Z",
        "rating": "novote",
        "publishedDate": "26 Jan 2026",
        "tags": [
          "LLM",
          "Agents",
          "Benchmark",
          "Games"
        ],
        "doi": "",
        "journalName": "ICLR 2026 Poster",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 26,
        "object_id": "paper:openreview.H1ncX6O6Yh",
        "created_at": "2026-02-08T22:18:39+00:00",
        "updated_at": "2026-02-08T22:18:55+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2503.15655": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2503.15655",
        "url": "https://arxiv.org/abs/2503.15655",
        "title": "R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs",
        "authors": "Zefeng Lin, Yi Xiao, Zhiqiang Mo, Qifan Zhang, Jie Wang, Jiayang Chen, Jiajing Zhang, Hui Zhang, Zhengyi Liu, Xianyong Fang, Xiaohua Xu",
        "abstract": "Automatically adapting novels into screenplays is important for the TV, film, or opera industries to promote products with low costs. The strong performances of large language models (LLMs) in long-text generation call us to propose a LLM based framework Reader-Rewriter (R2^2) for this task. However, there are two fundamental challenges here. First, the LLM hallucinations may cause inconsistent plot extraction and screenplay generation. Second, the causality-embedded plot lines should be effectively extracted for coherent rewriting. Therefore, two corresponding tactics are proposed: 1) A hallucination-aware refinement method (HAR) to iteratively discover and eliminate the affections of hallucinations; and 2) a causal plot-graph construction method (CPC) based on a greedy cycle-breaking algorithm to efficiently construct plot lines with event causalities. Recruiting those efficient techniques, R2^2 utilizes two modules to mimic the human screenplay rewriting process: The Reader module adopts a sliding window and CPC to build the causal plot graphs, while the Rewriter module generates first the scene outlines based on the graphs and then the screenplays. HAR is integrated into both modules for accurate inferences of LLMs. Experimental results demonstrate the superiority of R2^2, which substantially outperforms three existing approaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison at the overall win rate for GPT-4o.",
        "timestamp": "2026-02-08T22:18:27.981Z",
        "rating": "novote",
        "publishedDate": "2025/03/19",
        "tags": [
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 25,
        "object_id": "paper:arxiv.2503.15655",
        "created_at": "2026-02-08T22:18:28+00:00",
        "updated_at": "2026-02-08T22:18:47+00:00",
        "version": 1
      }
    },
    "paper:url.46149ECF": {
      "data": {
        "sourceId": "url",
        "paperId": "46149ECF",
        "url": "https://www.theatlantic.com/ideas/2026/02/books-news-washington-post/685897/?utm_source=feed",
        "title": "The Literary Ecosystem Is Dying",
        "authors": "Adam Kirsch",
        "abstract": "In a sense, the decline of book reviews, like the decline of newspapers themselves, is a story about disaggregation.",
        "timestamp": "2026-02-09T00:23:17.078Z",
        "rating": "novote",
        "publishedDate": "2026-02-06T12:00:00Z",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 27,
        "object_id": "paper:url.46149ECF",
        "created_at": "2026-02-09T00:23:17+00:00",
        "updated_at": "2026-02-09T00:23:35+00:00",
        "version": 1
      }
    },
    "paper:url.2DB787B1": {
      "data": {
        "sourceId": "url",
        "paperId": "2DB787B1",
        "url": "https://odd-lots-books.netlify.app/",
        "title": "Odd Lots Books",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T02:09:07.679Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 28,
        "object_id": "paper:url.2DB787B1",
        "created_at": "2026-02-09T02:09:07+00:00",
        "updated_at": "2026-02-09T02:09:29+00:00",
        "version": 1
      }
    },
    "paper:url.35111C3C": {
      "data": {
        "sourceId": "url",
        "paperId": "35111C3C",
        "url": "https://github.com/yanaiela/service",
        "title": "yanaiela/service: library for different service automation",
        "authors": "",
        "abstract": "library for different service automation. Contribute to yanaiela/service development by creating an account on GitHub.",
        "timestamp": "2026-02-09T13:48:20.134Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 29,
        "object_id": "paper:url.35111C3C",
        "created_at": "2026-02-09T13:48:20+00:00",
        "updated_at": "2026-02-09T13:48:40+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2510.18866": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2510.18866",
        "url": "https://arxiv.org/abs/2510.18866",
        "title": "LightMem: Lightweight and Efficient Memory-Augmented Generation",
        "authors": "Jizhan Fang, Xinle Deng, Haoming Xu, Ziyan Jiang, Yuqi Tang, Ziwen Xu, Shumin Deng, Yunzhi Yao, Mengru Wang, Shuofei Qiao, Huajun Chen, Ningyu Zhang",
        "abstract": "Despite their remarkable capabilities, Large Language Models (LLMs) struggle to effectively leverage historical interaction information in dynamic and complex environments. Memory systems enable LLMs to move beyond stateless interactions by introducing persistent information storage, retrieval, and utilization mechanisms. However, existing memory systems often introduce substantial time and computational overhead. To this end, we introduce a new memory system called LightMem, which strikes a balance between the performance and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of human memory, LightMem organizes memory into three complementary stages. First, cognition-inspired sensory memory rapidly filters irrelevant information through lightweight compression and groups information according to their topics. Next, topic-aware short-term memory consolidates these topic-based groups, organizing and summarizing content for more structured access. Finally, long-term memory with sleep-time update employs an offline procedure that decouples consolidation from online inference. On LongMemEval and LoCoMo, using GPT and Qwen backbones, LightMem consistently surpasses strong baselines, improving QA accuracy by up to 7.7% / 29.3%, reducing total token usage by up to 38x / 20.9x and API calls by up to 30x / 55.5x, while purely online test-time costs are even lower, achieving up to 106x / 117x token reduction and 159x / 310x fewer API calls. The code is available at this https URL.",
        "timestamp": "2026-02-09T13:49:29.819Z",
        "rating": "novote",
        "publishedDate": "2025/10/21",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Computer Vision and Pattern Recognition (cs.CV)",
          "Machine Learning (cs.LG)",
          "Multiagent Systems (cs.MA)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 30,
        "object_id": "paper:arxiv.2510.18866",
        "created_at": "2026-02-09T13:49:30+00:00",
        "updated_at": "2026-02-09T13:49:52+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.10387": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2601.10387",
        "url": "https://arxiv.org/abs/2601.10387",
        "title": "The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models",
        "authors": "Christina Lu, Jack Gallagher, Jonathan Michala, Kyle Fish, Jack Lindsey",
        "abstract": "Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an \"Assistant Axis,\" which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts \"persona drift,\" a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona.",
        "timestamp": "2026-02-09T13:50:07.328Z",
        "rating": "novote",
        "publishedDate": "2026/01/15",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 31,
        "object_id": "paper:arxiv.2601.10387",
        "created_at": "2026-02-09T13:50:07+00:00",
        "updated_at": "2026-02-09T13:50:32+00:00",
        "version": 1
      }
    },
    "paper:url.6D0A3CDE": {
      "data": {
        "sourceId": "url",
        "paperId": "6D0A3CDE",
        "url": "https://hedgehogreview.com/web-features/thr/posts/a-mosaic",
        "title": "A Mosaic",
        "authors": "",
        "abstract": "I was looking for a hobby in prison but I found an education.",
        "timestamp": "2026-02-09T13:54:31.443Z",
        "rating": "novote",
        "publishedDate": "2026-01-08T11:59:00-05:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 32,
        "object_id": "paper:url.6D0A3CDE",
        "created_at": "2026-02-09T13:54:31+00:00",
        "updated_at": "2026-02-09T13:54:56+00:00",
        "version": 1
      }
    },
    "paper:url.220759C8": {
      "data": {
        "sourceId": "url",
        "paperId": "220759C8",
        "url": "https://www.interconnects.ai/p/opus-46-vs-codex-53?utm_campaign=email-half-post&r=4w5a66&utm_source=substack&utm_medium=email",
        "title": "Opus 4.6 vs. Codex 5.3",
        "authors": "Nathan Lambert",
        "abstract": "On comparing models in 2026.",
        "timestamp": "2026-02-09T14:08:30.745Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 33,
        "object_id": "paper:url.220759C8",
        "created_at": "2026-02-09T14:08:31+00:00",
        "updated_at": "2026-02-09T14:08:52+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2506.18841": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2506.18841",
        "url": "https://arxiv.org/abs/2506.18841",
        "title": "LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning",
        "authors": "Yuhao Wu, Yushi Bai, Zhiqiang Hu, Roy Ka-Wei Lee, Juanzi Li",
        "abstract": "Ultra-long generation by large language models (LLMs) is a widely demanded scenario, yet it remains a significant challenge due to their maximum generation length limit and overall quality degradation as sequence length increases. Previous approaches, exemplified by LongWriter, typically rely on ''teaching'', which involves supervised fine-tuning (SFT) on synthetic long-form outputs. However, this strategy heavily depends on synthetic SFT data, which is difficult and costly to construct, often lacks coherence and consistency, and tends to be overly artificial and structurally monotonous. In this work, we propose an incentivization-based approach that, starting entirely from scratch and without relying on any annotated or synthetic data, leverages reinforcement learning (RL) to foster the emergence of ultra-long, high-quality text generation capabilities in LLMs. We perform RL training starting from a base model, similar to R1-Zero, guiding it to engage in reasoning that facilitates planning and refinement during the writing process. To support this, we employ specialized reward models that steer the LLM towards improved length control, writing quality, and structural formatting. Experimental evaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B, consistently outperforms traditional SFT methods on long-form writing tasks, achieving state-of-the-art results across all metrics on WritingBench and Arena-Write, and even surpassing 100B+ models such as DeepSeek R1 and Qwen3-235B. We open-source our data and model checkpoints under this https URL",
        "timestamp": "2026-02-09T15:15:17.616Z",
        "rating": "novote",
        "publishedDate": "2025/06/23",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 34,
        "object_id": "paper:arxiv.2506.18841",
        "created_at": "2026-02-09T15:15:17+00:00",
        "updated_at": "2026-02-09T15:15:40+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.04811": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.04811",
        "url": "https://arxiv.org/abs/2602.04811",
        "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization",
        "authors": "Jiarui Yuan, Tailin Jin, Weize Chen, Zeyuan Liu, Zhiyuan Liu, Maosong Sun",
        "abstract": "True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficulty rather than an inability to recall learned knowledge. We introduce SE-Bench, a diagnostic environment that obfuscates the NumPy library and its API doc into a pseudo-novel package with randomized identifiers. Agents are trained to internalize this package and evaluated on simple coding tasks without access to documentation, yielding a clean setting where tasks are trivial with the new API doc but impossible for base models without it. Our investigation reveals three insights: (1) the Open-Book Paradox, where training with reference documentation inhibits retention, requiring \"Closed-Book Training\" to force knowledge compression into weights; (2) the RL Gap, where standard RL fails to internalize new knowledge completely due to PPO clipping and negative gradients; and (3) the viability of Self-Play for internalization, proving models can learn from self-generated, noisy tasks when coupled with SFT, but not RL. Overall, SE-Bench establishes a rigorous diagnostic platform for self-evolution with knowledge internalization. Our code and dataset can be found at this https URL.",
        "timestamp": "2026-02-09T15:19:20.169Z",
        "rating": "novote",
        "publishedDate": "2026/02/04",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 36,
        "object_id": "paper:arxiv.2602.04811",
        "created_at": "2026-02-09T15:19:20+00:00",
        "updated_at": "2026-02-09T15:19:41+00:00",
        "version": 1
      }
    },
    "paper:url-misc.68D79817": {
      "data": {
        "sourceId": "url-misc",
        "paperId": "68D79817",
        "url": "https://aleximas.substack.com/p/someday-we-will-all-be-artists",
        "title": "Someday we will all be artists",
        "authors": "Alex Imas",
        "abstract": "How AI will change the nature of work and art",
        "timestamp": "2026-02-09T15:18:48.370Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 35,
        "object_id": "paper:url-misc.68D79817",
        "created_at": "2026-02-09T15:18:48+00:00",
        "updated_at": "2026-02-09T15:19:11+00:00",
        "version": 1
      }
    },
    "paper:url.6F62DF27": {
      "data": {
        "sourceId": "url",
        "paperId": "6F62DF27",
        "url": "https://huggingface.co/opendatalab/PDF-Extract-Kit-1.0",
        "title": "opendatalab/PDF-Extract-Kit-1.0 \u00b7 Hugging Face",
        "authors": "",
        "abstract": "We\u2019re on a journey to advance and democratize artificial intelligence through open source and open science.",
        "timestamp": "2026-02-09T15:51:48.576Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 37,
        "object_id": "paper:url.6F62DF27",
        "created_at": "2026-02-09T15:51:48+00:00",
        "updated_at": "2026-02-09T15:52:08+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2501.18099": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2501.18099",
        "url": "https://arxiv.org/abs/2501.18099",
        "title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge",
        "authors": "Swarnadeep Saha, Xian Li, Marjan Ghazvininejad, Jason Weston, Tianlu Wang",
        "abstract": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to capture the step-bystep reasoning process that underlies the final evaluation of a response. However, due to the lack of human annotated CoTs for evaluation, the required components and structure of effective reasoning traces remain understudied. Consequently, previous approaches often (1) constrain reasoning traces to hand-designed components, such as a list of criteria, reference answers, or verification questions and (2) structure them such that planning is intertwined with the reasoning for evaluation. In this work, we propose EvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge that first generates an unconstrained evaluation plan, followed by its execution, and then the final judgment. In a self-training loop, EvalPlanner iteratively optimizes over synthetically constructed evaluation plans and executions, leading to better final verdicts. Our method achieves a new state-of-the-art performance for generative reward models on RewardBench (with a score of 93.9), despite being trained on fewer amount of, and synthetically generated, preference pairs. Additional experiments on other benchmarks like RM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both planning and reasoning for building robust LLM-as-a-Judge reasoning models.",
        "timestamp": "2026-02-09T17:57:24.729Z",
        "rating": "novote",
        "publishedDate": "2025/01/30",
        "tags": [
          "Artificial Intelligence (cs.AI)",
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 40,
        "object_id": "paper:arxiv.2501.18099",
        "created_at": "2026-02-09T17:57:24+00:00",
        "updated_at": "2026-02-09T17:57:45+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.11900": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2504.11900",
        "url": "https://arxiv.org/abs/2504.11900",
        "title": "Finding Flawed Fictions: Evaluating Complex Reasoning in Language Models via Plot Hole Detection",
        "authors": "Kabir Ahuja, Melanie Sclar, Yulia Tsvetkov",
        "abstract": "Stories are a fundamental aspect of human experience. Engaging deeply with stories and spotting plot holes -- inconsistencies in a storyline that break the internal logic or rules of a story's world -- requires nuanced reasoning skills, including tracking entities and events and their interplay, abstract thinking, pragmatic narrative understanding, commonsense and social reasoning, and theory of mind. As Large Language Models (LLMs) increasingly generate, interpret, and modify text, rigorously assessing their narrative consistency and deeper language understanding becomes critical. However, existing benchmarks focus mainly on surface-level comprehension. In this work, we propose plot hole detection in stories as a proxy to evaluate language understanding and reasoning in LLMs. We introduce FlawedFictionsMaker, a novel algorithm to controllably and carefully synthesize plot holes in human-written stories. Using this algorithm, we construct a benchmark to evaluate LLMs' plot hole detection abilities in stories -- FlawedFictions -- , which is robust to contamination, with human filtering ensuring high quality. We find that state-of-the-art LLMs struggle in accurately solving FlawedFictions regardless of the reasoning effort allowed, with performance significantly degrading as story length increases. Finally, we show that LLM-based story summarization and story generation are prone to introducing plot holes, with more than 50% and 100% increases in plot hole detection rates with respect to human-written originals.",
        "timestamp": "2026-02-09T18:33:04.122Z",
        "rating": "novote",
        "publishedDate": "2025/04/16",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 41,
        "object_id": "paper:arxiv.2504.11900",
        "created_at": "2026-02-09T18:33:04+00:00",
        "updated_at": "2026-02-09T18:33:26+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.11868": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2601.11868",
        "url": "https://arxiv.org/abs/2601.11868",
        "title": "Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces",
        "authors": "Mike A. Merrill, Alexander G. Shaw, Nicholas Carlini, Boxuan Li, Harsh Raj, Ivan Bercovich, Lin Shi, Jeong Yeon Shin, Thomas Walshe, E. Kelly Buchanan, Junhong Shen, Guanghao Ye, Haowei Lin, Jason Poulos, Maoyu Wang, Marianna Nezhurina, Jenia Jitsev, Di Lu, Orfeas Menis Mastromichalakis, Zhiwei Xu, Zizhao Chen, Yue Liu, Robert Zhang, Leon Liangyu Chen, Anurag Kashyap, Jan-Lucas Uslu, Jeffrey Li, Jianbo Wu, Minghao Yan, Song Bian, Vedang Sharma, Ke Sun, Steven Dillmann, Akshay Anand, Andrew Lanpouthakoun, Bardia Koopah, Changran Hu, Etash Guha, Gabriel H. S. Dreiman, Jiacheng Zhu, Karl Krauth, Li Zhong, Niklas Muennighoff, Robert Amanfu, Shangyin Tan, Shreyas Pimpalgaonkar, Tushar Aggarwal, Xiangning Lin, Xin Lan, Xuandong Zhao, Yiqing Liang, Yuanli Wang, Zilong Wang, Changzhi Zhou, David Heineman, Hange Liu, Harsh Trivedi, John Yang, Junhong Lin, Manish Shetty, Michael Yang, Nabil Omi, Negin Raoof, Shanda Li, Terry Yue Zhuo, Wuwei Lin, Yiwei Dai, Yuxin Wang, Wenhao Chai, Shang Zhou, Dariush Wahdany, Ziyu She, Jiaming Hu, Zhikang Dong, Yuxuan Zhu, Sasha Cui, Ahson Saiyed, Arinbj\u00f6rn Kolbeinsson, Jesse Hu, Christopher Michael Rytting, Ryan Marten, Yixin Wang, Alex Dimakis, Andy Konwinski, Ludwig Schmidt",
        "abstract": "AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at this https URL .",
        "timestamp": "2026-02-09T20:53:37.369Z",
        "rating": "novote",
        "publishedDate": "2026/01/17",
        "tags": [
          "Software Engineering (cs.SE)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 43,
        "object_id": "paper:arxiv.2601.11868",
        "created_at": "2026-02-09T20:53:37+00:00",
        "updated_at": "2026-02-09T20:53:57+00:00",
        "version": 1
      }
    },
    "paper:url.26DA80ED": {
      "data": {
        "sourceId": "url",
        "paperId": "26DA80ED",
        "url": "https://anthology.ach.org/",
        "title": "Anthology of Computers and the Humanities",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T20:56:26.187Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 44,
        "object_id": "paper:url.26DA80ED",
        "created_at": "2026-02-09T20:56:26+00:00",
        "updated_at": "2026-02-09T20:57:13+00:00",
        "version": 1
      }
    },
    "paper:url.5DD06E7F": {
      "data": {
        "sourceId": "url",
        "paperId": "5DD06E7F",
        "url": "https://anthology.ach.org/volumes/vol0003/cultural-collapse-toward-generative-formalism-for/",
        "title": "Cultural Collapse: Toward a Generative Formalism for AI Cultural\nProduction",
        "authors": "Heuser, Ryan",
        "abstract": "This paper examines systematic patterns of idealization in large\nlanguage model outputs through computational analysis of over 15,000\nAI-generated poems and artificial bibliographic data. The study reveals\nand theorizes \u2018cultural collapse\u2019\u2014the tendency of LLMs to generate\ncultural content that is more formulaic and idealized than can be\nobserved in any historical period. Analysis of rhyme patterns shows that\nmodels produce formally conservative verse at rates that exceed even the\nmost traditional historical periods. This bias persists even when models\nare explicitly instructed against traditional forms and cannot be\nexplained by training data composition, suggesting deep computational\ntendencies toward idealization. Extending beyond poetics, parallel\npatterns emerge in historical domains: when prompted to generate\nhistorical publication data, models systematically produce demographic\ndistributions that obscure well-known exclusion patterns, creating\nrevisionist narratives where marginalized authors were published at\nrates far exceeding historical reality. The study identifies instruction\ntuning as one contributing mechanism, with models fine-tuned to be\nhelpful assistants showing significantly greater \u2018idealization\u2019 than\nbase models. These findings suggest that cultural collapse operates\nthrough a computational logic that privileges satisfaction over\nfrustration, regularity over variation, and conformity over\ncontradiction. As generative systems become ubiquitous in cultural\nproduction, their idealizing tendencies threaten to flatten cultural\ndiversity and historical complexity, requiring new critical frameworks\nfor understanding computational mediation of cultural transmission.",
        "timestamp": "2026-02-09T20:58:08.450Z",
        "rating": "novote",
        "publishedDate": "2025",
        "tags": [],
        "doi": "10.63744/USvuyzSIapvy",
        "journalName": "Anthology of Computers and the Humanities",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 45,
        "object_id": "paper:url.5DD06E7F",
        "created_at": "2026-02-09T20:58:08+00:00",
        "updated_at": "2026-02-09T20:58:31+00:00",
        "version": 1
      }
    },
    "paper:url.6D647947": {
      "data": {
        "sourceId": "url",
        "paperId": "6D647947",
        "url": "https://techxplore.com/news/2018-09-behavior-goodreads-amazon-bestsellers.html",
        "title": "Analyzing book reading behavior on Goodreads to predict Amazon Bestsellers",
        "authors": "",
        "abstract": "Researchers at Northwestern University, Microsoft Research India, and the Indian Institute of Technology Kharagpur have recently developed a model to predict whether a book will become a bestseller on Amazon within 15 days of its publication. Their model, outlined in a study pre-published on arXiv, works by analyzing reading behavior on the online platform Goodreads.",
        "timestamp": "2026-02-09T21:13:48.739Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "hi-tech news",
          "hitech",
          "innovation",
          "inventions",
          "computer news",
          "information technology"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 47,
        "object_id": "paper:url.6D647947",
        "created_at": "2026-02-09T21:13:49+00:00",
        "updated_at": "2026-02-09T21:14:12+00:00",
        "version": 1
      }
    },
    "paper:url.30331C8C": {
      "data": {
        "sourceId": "url",
        "paperId": "30331C8C",
        "url": "https://www.semanticscholar.org/paper/Who-decides-what-is-read-on-Goodreads-Uncovering-Hu-Diesner/4f53942e0621d172ae60ec090ecd76fc012fb6f8",
        "title": "The Goodreads \u201cClassics\u201d: A Computational Study of Readers, Amazon, and Crowdsourced Amateur Criticism",
        "authors": "Melanie Walsh, Maria Antoniak",
        "abstract": "The scale of the phenomena of incentivized book reviews is revealed for the first time, which illuminates the rise of sponsored content while contributing to broader discussions on computational approaches to digital economies of prestige and the responsible use of platform-mediated cultural datasets across disciplines. Attracted by the promise of a broader and more egalitarian sample of readers than published book reviews provide, researchers are increasingly scraping social reviewing platforms like Goodreads for data about readers\u2019 behavior. Yet, treating online book reviews as direct proxies for readers and books can be problematic, as they are socially and technically constructed artifacts shaped by platform dynamics, whether between developers and users, or book industry stakeholders and reviewers. To uncover these complexities, we computationally curated 331,211 self-identified incentivized book reviews to understand the growth of incentivized content, and how these purportedly equal-access social reviewing spaces are re-inscribing the inequalities of traditional book reviewing and publishing. Our findings underscore the necessity of critical examination of both online book reviewing and cultural datasets derived from social media platforms. With the growing restrictions on access to platform data for research, this study also demonstrates the potential for a mixed-method analysis of historical scraped datasets; an approach that will likely be of interest to many researchers working with cultural data moderated by black-box algorithms. With this method, our research reveals for the first time the scale of the phenomena of incentivized book reviews that is well known to users of Goodreads but remains largely anecdotal. Additionally, it illuminates the rise of sponsored content while contributing to broader discussions on computational approaches to digital economies of prestige and the responsible use of platform-mediated cultural datasets across disciplines.",
        "timestamp": "2026-02-09T21:13:37.301Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "Journal of Cultural Analytics",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 46,
        "object_id": "paper:url.30331C8C",
        "created_at": "2026-02-09T21:13:37+00:00",
        "updated_at": "2026-02-09T21:13:59+00:00",
        "version": 1
      }
    },
    "paper:url.64A6F94C": {
      "data": {
        "sourceId": "url",
        "paperId": "64A6F94C",
        "url": "https://www.publishersweekly.com/pw/by-topic/digital/copyright/article/99019-new-report-examines-writers-attitudes-toward-ai.html",
        "title": "New Report Examines Writers\u2019 Attitudes toward AI",
        "authors": "",
        "abstract": "A study commissioned by the Gotham Ghostwriters and Bernoff.com found that while 61% of professional writers are embracing AI tools, authors, specifically fiction authors, are much more wary.",
        "timestamp": "2026-02-09T21:16:19.122Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "Gotham Ghostwriters",
          "Josh Bernoff",
          "AI",
          "Chat GPT"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 50,
        "object_id": "paper:url.64A6F94C",
        "created_at": "2026-02-09T21:16:19+00:00",
        "updated_at": "2026-02-09T21:16:39+00:00",
        "version": 1
      }
    },
    "paper:url.1EB56418": {
      "data": {
        "sourceId": "url",
        "paperId": "1EB56418",
        "url": "https://insights.bookbub.com/how-authors-are-thinking-about-ai-survey/",
        "title": "How Authors Are Thinking About AI (Survey of 1,200+ Authors)",
        "authors": "Carlyn Robertson",
        "abstract": "We surveyed more than 1,200 authors to learn how they're thinking about generative AI as it relates to their work. Here's what they had to say.",
        "timestamp": "2026-02-09T21:16:09.683Z",
        "rating": "novote",
        "publishedDate": "2025-05-15T13:04:25+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 49,
        "object_id": "paper:url.1EB56418",
        "created_at": "2026-02-09T21:16:09+00:00",
        "updated_at": "2026-02-09T21:16:29+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2502.09747": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2502.09747",
        "url": "https://arxiv.org/abs/2502.09747",
        "title": "The Widespread Adoption of Large Language Model-Assisted Writing Across Society",
        "authors": "Weixin Liang, Yaohui Zhang, Mihai Codreanu, Jiayu Wang, Hancheng Cao, James Zou",
        "abstract": "The recent advances in large language models (LLMs) attracted significant public and policymaker interest in its adoption patterns. In this paper, we systematically analyze LLM-assisted writing across four domains-consumer complaints, corporate communications, job postings, and international organization press releases-from January 2022 to September 2024. Our dataset includes 687,241 consumer complaints, 537,413 corporate press releases, 304.3 million job postings, and 15,919 United Nations (UN) press releases. Using a robust population-level statistical framework, we find that LLM usage surged following the release of ChatGPT in November 2022. By late 2024, roughly 18% of financial consumer complaint text appears to be LLM-assisted, with adoption patterns spread broadly across regions and slightly higher in urban areas. For corporate press releases, up to 24% of the text is attributable to LLMs. In job postings, LLM-assisted writing accounts for just below 10% in small firms, and is even more common among younger firms. UN press releases also reflect this trend, with nearly 14% of content being generated or modified by LLMs. Although adoption climbed rapidly post-ChatGPT, growth appears to have stabilized by 2024, reflecting either saturation in LLM adoption or increasing subtlety of more advanced models. Our study shows the emergence of a new reality in which firms, consumers and even international organizations substantially rely on generative AI for communications.",
        "timestamp": "2026-02-09T21:15:40.332Z",
        "rating": "novote",
        "publishedDate": "2025/02/13",
        "tags": [
          "Computation and Language (cs.CL)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 48,
        "object_id": "paper:arxiv.2502.09747",
        "created_at": "2026-02-09T21:15:40+00:00",
        "updated_at": "2026-02-09T21:16:04+00:00",
        "version": 1
      }
    },
    "paper:url.114087CA": {
      "data": {
        "sourceId": "url",
        "paperId": "114087CA",
        "url": "https://www.bookautoai.com/",
        "title": "The #1 Non-Fiction Writer",
        "authors": "",
        "abstract": "Turn your ideas into a masterpiece\u2014humanized, polished, and platform-ready. Let BookAutoAI bring your story to life!",
        "timestamp": "2026-02-09T21:21:07.790Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 51,
        "object_id": "paper:url.114087CA",
        "created_at": "2026-02-09T21:21:08+00:00",
        "updated_at": "2026-02-09T21:21:29+00:00",
        "version": 1
      }
    },
    "paper:url.6A293AC6": {
      "data": {
        "sourceId": "url",
        "paperId": "6A293AC6",
        "url": "https://lostbooks.ca/",
        "title": "Lost Books \u2013 AI-Assisted Dystopian Sci-Fi by Tim Boucher",
        "authors": "",
        "abstract": "",
        "timestamp": "2026-02-09T21:25:33.178Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 52,
        "object_id": "paper:url.6A293AC6",
        "created_at": "2026-02-09T21:25:33+00:00",
        "updated_at": "2026-02-09T21:25:51+00:00",
        "version": 1
      }
    },
    "paper:url.7274CFA9": {
      "data": {
        "sourceId": "url",
        "paperId": "7274CFA9",
        "url": "https://www.newsweek.com/ai-books-art-money-artificial-intelligence-1799923",
        "title": "\"I'm making thousands using AI to write books\"",
        "authors": "",
        "abstract": "This approach has been successful. I have an unprecedented rate of production.",
        "timestamp": "2026-02-09T21:26:25.796Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 53,
        "object_id": "paper:url.7274CFA9",
        "created_at": "2026-02-09T21:26:26+00:00",
        "updated_at": "2026-02-09T21:26:48+00:00",
        "version": 1
      }
    },
    "paper:url.2F912D55": {
      "data": {
        "sourceId": "url",
        "paperId": "2F912D55",
        "url": "https://www.publicbooks.org/defending-the-possibility-of-the-university-a-roundtable-on-university-keywords/",
        "title": "Defending the Possibility of the University: A Roundtable on \u201cUniversity Keywords\u201d - Public Books",
        "authors": "Megan Cummins",
        "abstract": "\u201cWhat would it look like for faculty unions and graduate student unions to collaborate or work together with K-12 teachers\u2019 unions to push back against anti-DEI legislation or book bans?\u201d",
        "timestamp": "2026-02-09T21:28:30.011Z",
        "rating": "novote",
        "publishedDate": "2026-02-04T16:00:00+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 54,
        "object_id": "paper:url.2F912D55",
        "created_at": "2026-02-09T21:28:30+00:00",
        "updated_at": "2026-02-09T21:28:53+00:00",
        "version": 1
      }
    },
    "paper:url.1EA16CE": {
      "data": {
        "sourceId": "url",
        "paperId": "1EA16CE",
        "url": "https://www.publicbooks.org/how-translations-sell-three-u-s-eras-of-international-bestsellers/",
        "title": "How Translations Sell: Three U.S. Eras of International Bestsellers - Public Books",
        "authors": "Megan Cummins",
        "abstract": "A translation renaissance in US publishing just ended. And you probably missed it.",
        "timestamp": "2026-02-09T21:30:06.854Z",
        "rating": "novote",
        "publishedDate": "2025-09-16T15:00:31+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 56,
        "object_id": "paper:url.1EA16CE",
        "created_at": "2026-02-09T21:30:07+00:00",
        "updated_at": "2026-02-09T21:30:44+00:00",
        "version": 1
      }
    },
    "paper:url.5BC116CB": {
      "data": {
        "sourceId": "url",
        "paperId": "5BC116CB",
        "url": "https://www.publicbooks.org/on-our-nightstands-september-2023/",
        "title": "On Our Nightstands: September 2023 - Public Books",
        "authors": "Imani Radney",
        "abstract": "A behind-the-scenes look at what \u201cPublic Books\u201d editors and staff have been reading this month.",
        "timestamp": "2026-02-09T21:29:53.905Z",
        "rating": "novote",
        "publishedDate": "2023-09-08T15:00:33+00:00",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 55,
        "object_id": "paper:url.5BC116CB",
        "created_at": "2026-02-09T21:29:54+00:00",
        "updated_at": "2026-02-09T21:30:15+00:00",
        "version": 1
      }
    },
    "paper:url.3240606D": {
      "data": {
        "sourceId": "url",
        "paperId": "3240606D",
        "url": "https://billieleelucas.medium.com/how-i-made-73-dollars-with-amazon-kdp-today-a-full-bookautoai-review-8b14c810f9fd",
        "title": "How I Made $73 Dollars With Amazon KDP Today |a Full BookAutoAI Review",
        "authors": "Billie Lee Lucas",
        "abstract": "How I Made $73 Dollars With Amazon KDP Today | a Full BookAutoAI Review I made $73 today so far. I know it\u2019s less than the hundreds I\u2019ve shown before, but this is another one of my accounts that \u2026",
        "timestamp": "2026-02-09T21:31:28.298Z",
        "rating": "novote",
        "publishedDate": "2025-09-25T04:15:17.390Z",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 57,
        "object_id": "paper:url.3240606D",
        "created_at": "2026-02-09T21:31:28+00:00",
        "updated_at": "2026-02-09T21:31:48+00:00",
        "version": 1
      }
    },
    "paper:url.5977F244": {
      "data": {
        "sourceId": "url",
        "paperId": "5977F244",
        "url": "https://www.goodreads.com/list/show/219041.Books_I_Have_No_Doubt_Are_Written_By_A_I_",
        "title": "Books I Have No Doubt Are Written By A.I. (97 books) | Goodreads",
        "authors": "",
        "abstract": "97 books based on 9 votes: Elven Blood by Mark Stanley, Battle Mage (Volume 2 of the Vellhor Saga): A Fantasy Realms Novel by Mark Stanley, Dwarven Princ...",
        "timestamp": "2026-02-09T21:33:56.785Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 59,
        "object_id": "paper:url.5977F244",
        "created_at": "2026-02-09T21:33:57+00:00",
        "updated_at": "2026-02-09T21:34:20+00:00",
        "version": 1
      }
    },
    "paper:url.5F9A774A": {
      "data": {
        "sourceId": "url",
        "paperId": "5F9A774A",
        "url": "https://www.goodreads.com/list/tag/ai-book",
        "title": "Ai Book Book Lists | Goodreads",
        "authors": "",
        "abstract": "Lists about: Books I Have No Doubt Are Written By A.I., Undoubtedly an AI book, ChatGPT AI cover art , AI books published in October 2025, Yes, AI slop i...",
        "timestamp": "2026-02-09T21:33:43.554Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 58,
        "object_id": "paper:url.5F9A774A",
        "created_at": "2026-02-09T21:33:43+00:00",
        "updated_at": "2026-02-09T21:34:04+00:00",
        "version": 1
      }
    }
  }
}