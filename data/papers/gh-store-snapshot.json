{
  "snapshot_time": "2026-02-08T21:33:49.402127+00:00",
  "repository": "chtmp223/papers-feed",
  "objects": {
    "paper:nber.w34777": {
      "data": {
        "rating": "novote",
        "doi": "10.3386/w34777",
        "timestamp": "2026-02-08T01:07:44.172Z",
        "abstract": "Founded in 1920, the NBER is a private, non-profit, non-partisan organization dedicated to conducting economic research and to disseminating research findings among academics, public policy makers, and business professionals.",
        "url": "https://www.nber.org/papers/w34777",
        "authors": "Imke Reimers, Joel Waldfogel",
        "publishedDate": "2026/02/02",
        "title": "AI and the Quantity and Quality of Creative Products: Have LLMs Boosted Creation of Valuable Books?",
        "sourceId": "nber",
        "tags": [
          "Imke Reimers",
          "Joel Waldfogel"
        ],
        "paperId": "w34777",
        "journalName": "NBER Working Papers",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 12,
        "object_id": "paper:nber.w34777",
        "created_at": "2026-02-08T01:07:44+00:00",
        "updated_at": "2026-02-08T01:08:12+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.05125": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T01:23:36.193Z",
        "abstract": "Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, conflate dimensions, misalign preference direction, and contain redundant or highly correlated criteria, degrading judge accuracy and producing suboptimal rewards during RFT. We propose RRD, a principled framework for rubric refinement built on a recursive decompose-filter cycle. RRD decomposes coarse rubrics into fine-grained, discriminative criteria, expanding coverage while sharpening separation between responses. A complementary filtering mechanism removes misaligned and redundant rubrics, and a correlation-aware weighting scheme prevents over-representing highly correlated criteria, yielding rubric sets that are informative, comprehensive, and non-redundant. Empirically, RRD delivers large, consistent gains across both evaluation and training: it improves preference-judgment accuracy on JudgeBench and PPE for both GPT-4o and Llama3.1-405B judges, achieving top performance in all settings with up to +17.7 points on JudgeBench. When used as the reward source for RFT on WildChat, it yields substantially stronger and more stable learning signals, boosting reward by up to 160% (Qwen3-4B) and 60% (Llama3.1-8B) versus 10-20% for prior rubric baselines, with gains that transfer to HealthBench-Hard and BiGGen Bench. Overall, RRD establishes recursive rubric refinement as a scalable and interpretable foundation for LLM judging and reward modeling in open-ended domains.",
        "url": "https://arxiv.org/abs/2602.05125",
        "authors": "William F. Shen, Xinchi Qiu, Chenxi Whitehouse, Lisa Alazraki, Shashwat Goel, Francesco Barbieri, Timon Willi, Akhil Mathur, Ilias Leontiadis",
        "publishedDate": "2026/02/04",
        "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)",
          "Artificial Intelligence (cs.AI)"
        ],
        "paperId": "2602.05125",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 13,
        "object_id": "paper:arxiv.2602.05125",
        "created_at": "2026-02-08T01:23:36+00:00",
        "updated_at": "2026-02-08T01:23:54+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2601.21996": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:10:02.187Z",
        "abstract": "While Mechanistic Interpretability has identified interpretable circuits in LLMs, their causal origins in training data remain elusive. We introduce Mechanistic Data Attribution (MDA), a scalable framework that employs Influence Functions to trace interpretable units back to specific training samples. Through extensive experiments on the Pythia family, we causally validate that targeted intervention--removing or augmenting a small fraction of high-influence samples--significantly modulates the emergence of interpretable heads, whereas random interventions show no effect. Our analysis reveals that repetitive structural data (e.g., LaTeX, XML) acts as a mechanistic catalyst. Furthermore, we observe that interventions targeting induction head formation induce a concurrent change in the model's in-context learning (ICL) capability. This provides direct causal evidence for the long-standing hypothesis regarding the functional link between induction heads and ICL. Finally, we propose a mechanistic data augmentation pipeline that consistently accelerates circuit convergence across model scales, providing a principled methodology for steering the developmental trajectories of LLMs.",
        "url": "https://arxiv.org/abs/2601.21996",
        "authors": "Jianhui Chen, Yuzhang Luo, Liangming Pan",
        "publishedDate": "2026/01/29",
        "title": "Mechanistic Data Attribution: Tracing the Training Origins of Interpretable LLM Units",
        "sourceId": "arxiv",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)",
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2601.21996",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 15,
        "object_id": "paper:arxiv.2601.21996",
        "created_at": "2026-02-08T02:10:02+00:00",
        "updated_at": "2026-02-08T02:10:26+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2504.12501": {
      "data": {
        "rating": "novote",
        "doi": "",
        "timestamp": "2026-02-08T02:09:57.564Z",
        "abstract": "Reinforcement learning from human feedback (RLHF) has become an important technical and storytelling tool to deploy the latest machine learning systems. In this book, we hope to give a gentle introduction to the core methods for people with some level of quantitative background. The book starts with the origins of RLHF -- both in recent literature and in a convergence of disparate fields of science in economics, philosophy, and optimal control. We then set the stage with definitions, problem formulation, data collection, and other common math used in the literature. The core of the book details every optimization stage in using RLHF, from starting with instruction tuning to training a reward model and finally all of rejection sampling, reinforcement learning, and direct alignment algorithms. The book concludes with advanced topics -- understudied research questions in synthetic data and evaluation -- and open questions for the field.",
        "url": "https://arxiv.org/abs/2504.12501",
        "authors": "Nathan Lambert",
        "publishedDate": "2025/04/16",
        "title": "Reinforcement Learning from Human Feedback",
        "sourceId": "arxiv",
        "tags": [
          "Machine Learning (cs.LG)"
        ],
        "paperId": "2504.12501",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 14,
        "object_id": "paper:arxiv.2504.12501",
        "created_at": "2026-02-08T02:09:57+00:00",
        "updated_at": "2026-02-08T02:10:16+00:00",
        "version": 1
      }
    },
    "paper:arxiv.2602.03183": {
      "data": {
        "sourceId": "arxiv",
        "paperId": "2602.03183",
        "url": "https://arxiv.org/abs/2602.03183",
        "title": "Privasis: Synthesizing the Largest \"Public\" Private Dataset from Scratch",
        "authors": "Hyunwoo Kim, Niloofar Mireshghallah, Michael Duan, Rui Xin, Shuyue Stella Li, Jaehun Jung, David Acuna, Qi Pang, Hanshen Xiao, G. Edward Suh, Sewoong Oh, Yulia Tsvetkov, Pang Wei Koh, Yejin Choi",
        "abstract": "Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.",
        "timestamp": "2026-02-08T15:57:27.140Z",
        "rating": "novote",
        "publishedDate": "2026/02/03",
        "tags": [
          "Computation and Language (cs.CL)",
          "Artificial Intelligence (cs.AI)"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 16,
        "object_id": "paper:arxiv.2602.03183",
        "created_at": "2026-02-08T15:57:27+00:00",
        "updated_at": "2026-02-08T15:59:45+00:00",
        "version": 1
      }
    },
    "paper:url.7BCFC2D3": {
      "data": {
        "sourceId": "url",
        "paperId": "7BCFC2D3",
        "url": "https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/",
        "title": "I Am Happier Writing Code by Hand",
        "authors": "Abhinav Omprakash",
        "abstract": "I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work and my phone. \u201cWhat\u2019s the point of it all?\u201d I thought, LLMs can generate decent-ish and correct-ish looking code while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow?",
        "timestamp": "2026-02-08T16:11:42.767Z",
        "rating": "novote",
        "publishedDate": "2026-02-07T15:30:23+02:00",
        "tags": [
          "essays"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 17,
        "object_id": "paper:url.7BCFC2D3",
        "created_at": "2026-02-08T16:11:42+00:00",
        "updated_at": "2026-02-08T16:12:02+00:00",
        "version": 1
      }
    },
    "paper:url.64A41AB2": {
      "data": {
        "sourceId": "url",
        "paperId": "64A41AB2",
        "url": "https://siddhantkhare.com/writing/ai-fatigue-is-real",
        "title": "AI fatigue is real and nobody talks about it | Siddhant Khare",
        "authors": "Siddhant Khare",
        "abstract": "You're using AI to be more productive. So why are you more exhausted than ever? The paradox every engineer needs to confront.",
        "timestamp": "2026-02-08T16:30:33.826Z",
        "rating": "novote",
        "publishedDate": "2026-02-08",
        "tags": [
          "Siddhant Khare",
          "AI agent infrastructure",
          "LLM agents",
          "agentic AI",
          "AI security",
          "OpenFGA",
          "CNCF",
          "memory systems",
          "authorization",
          "ReBAC",
          "agent orchestration",
          "context engineering",
          "context efficiency",
          "RAG deduplication",
          "KV-cache",
          "inference optimization",
          "software engineer",
          "open source",
          "Gitpod",
          "Ona",
          "machine learning infrastructure",
          "Zanzibar authorization",
          "distributed systems",
          "GPU profiling",
          "MCP servers"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 19,
        "object_id": "paper:url.64A41AB2",
        "created_at": "2026-02-08T16:30:34+00:00",
        "updated_at": "2026-02-08T16:30:53+00:00",
        "version": 1
      }
    },
    "paper:url.4F5694F4": {
      "data": {
        "sourceId": "url",
        "paperId": "4F5694F4",
        "url": "https://daplab.cs.columbia.edu/general/2026/01/07/why-vibe-coding-fails-and-how-to-fix-it.html",
        "title": "DAPLab - Data, Agents, and Processes | Columbia University",
        "authors": "DAPLab, Columbia University",
        "abstract": "A research lab at Columbia University working at the intersection of AI, systems, and automation.",
        "timestamp": "2026-02-08T16:30:05.829Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [
          "DAPLab",
          "Columbia University",
          "agent-based systems",
          "systems research",
          "AI safety",
          "RL",
          "ML",
          "HCI",
          "cloud computing",
          "large language models",
          "trustworthy AI",
          "automation research",
          "operations research"
        ],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 18,
        "object_id": "paper:url.4F5694F4",
        "created_at": "2026-02-08T16:30:06+00:00",
        "updated_at": "2026-02-08T16:30:24+00:00",
        "version": 1
      }
    },
    "paper:url.7744C59C": {
      "data": {
        "sourceId": "url",
        "paperId": "7744C59C",
        "url": "https://aeon.co/videos/the-elaborate-places-ones-mind-wanders-in-solitary-confinement?utm_source=rss-feed",
        "title": "The elaborate places one\u2019s mind wanders in solitary confinement | Aeon Videos",
        "authors": "",
        "abstract": "Where does the mind go in solitary confinement? An evocative animation exploring three individual experiences",
        "timestamp": "2026-02-08T17:02:29.616Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 20,
        "object_id": "paper:url.7744C59C",
        "created_at": "2026-02-08T17:02:29+00:00",
        "updated_at": "2026-02-08T17:02:47+00:00",
        "version": 1
      }
    },
    "paper:url.214C1B64": {
      "data": {
        "sourceId": "url",
        "paperId": "214C1B64",
        "url": "https://ezhik.jp/ai-slop-terrifies-me/",
        "title": "(AI) Slop Terrifies Me \u2013 ezhik.jp",
        "authors": "",
        "abstract": "What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring?",
        "timestamp": "2026-02-08T17:04:48.390Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 22,
        "object_id": "paper:url.214C1B64",
        "created_at": "2026-02-08T17:04:48+00:00",
        "updated_at": "2026-02-08T17:05:05+00:00",
        "version": 1
      }
    },
    "paper:url-misc.223BF1B6": {
      "data": {
        "sourceId": "url-misc",
        "paperId": "223BF1B6",
        "url": "https://pubmed.ncbi.nlm.nih.gov/41506004/",
        "title": "Blood omega-3 is inversely related to risk of early-onset dementia",
        "authors": "",
        "abstract": "This study expands the evidence of a beneficial association of omega-3 and LOD to EOD as well. These findings suggest that an increased intake of omega-3 fatty acids earlier in life may slow the development of EOD. Additional research is needed to confirm our findings, particularly in more diverse p \u2026",
        "timestamp": "2026-02-08T17:04:30.033Z",
        "rating": "novote",
        "publishedDate": "2026 Feb",
        "tags": [
          "pmid:41506004",
          "doi:10.1016/j.clnu.2025.106559",
          "Aleix Sala-Vila",
          "Nathan L Tintle",
          "William S Harris",
          "Adult",
          "Age of Onset",
          "Apolipoprotein E4 / genetics",
          "Cohort Studies",
          "Dementia* / blood",
          "Dementia* / epidemiology",
          "Dementia* / genetics",
          "Dementia* / prevention & control",
          "Diet* / statistics & numerical data",
          "Fatty Acids",
          "Omega-3* / blood",
          "Female",
          "Humans",
          "Male",
          "Middle Aged",
          "Proportional Hazards Models",
          "Risk Factors",
          "United Kingdom / epidemiology",
          "PubMed Abstract",
          "NIH",
          "NLM",
          "NCBI",
          "National Institutes of Health",
          "National Center for Biotechnology Information",
          "National Library of Medicine",
          "MEDLINE"
        ],
        "doi": "10.1016/j.clnu.2025.106559",
        "journalName": "Clinical nutrition (Edinburgh, Scotland)",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 21,
        "object_id": "paper:url-misc.223BF1B6",
        "created_at": "2026-02-08T17:04:30+00:00",
        "updated_at": "2026-02-08T17:04:50+00:00",
        "version": 1
      }
    },
    "paper:url.756E9B46": {
      "data": {
        "sourceId": "url",
        "paperId": "756E9B46",
        "url": "https://platform.claude.com/docs/en/agent-sdk/overview",
        "title": "Agent SDK overview",
        "authors": "",
        "abstract": "Build production AI agents with Claude Code as a library",
        "timestamp": "2026-02-08T21:33:07.955Z",
        "rating": "novote",
        "publishedDate": "",
        "tags": [],
        "doi": "",
        "journalName": "",
        "sourceType": "url"
      },
      "meta": {
        "issue_number": 23,
        "object_id": "paper:url.756E9B46",
        "created_at": "2026-02-08T21:33:08+00:00",
        "updated_at": "2026-02-08T21:33:27+00:00",
        "version": 1
      }
    }
  }
}